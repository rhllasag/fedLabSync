{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26552b7a",
   "metadata": {},
   "source": [
    " # Custom training with tf.distribute.Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc9a2d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import math\n",
    "import pandas as pd\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "from itertools import chain\n",
    "import os\n",
    "import random\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "print(tf.__version__)\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv1D, Conv2D, MaxPooling2D, Reshape\n",
    "from keras.optimizers import SGD\n",
    "from keras import optimizers\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import  keras\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "#tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017ed224",
   "metadata": {},
   "source": [
    "## Create a strategy to distribute the variables and the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce3d337e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    }
   ],
   "source": [
    "# If the list of devices is not specified in\n",
    "# `tf.distribute.MirroredStrategy` constructor, they will be auto-detected.\n",
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d784e6ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 1\n"
     ]
    }
   ],
   "source": [
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "d1a84a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.enable_eager_execution()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538af070",
   "metadata": {},
   "source": [
    "# Splitting data by Turbofan Unit\n",
    "\n",
    "## Defining IDS per node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3bf03ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_DATASET = 4\n",
    "FEATURES_PERCENTAGE = 1\n",
    "VAL_PERCENTAGE = 0.85\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 540\n",
    "LEARNING_RATE = 0.01\n",
    "OUT_PATH = \"data/cmapss/processed/\"\n",
    "train_df = pq.read_table(OUT_PATH + 'train_fd00' + str(NUMBER_OF_DATASET)+'.parquet').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "35c789f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming columns to training the model \n",
    "SENSOR_COLS = ['s2','s3','s4','s5','s6','s7', 's8','s9','s11','s12','s13','s14','s15','s17','s20','s21']\n",
    "SEQUENCE_COLS = ['RUL']\n",
    "TARGET_COLS = ['RUL']\n",
    "SEQUENCE_COLS.extend(SENSOR_COLS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "cecd725b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=10\n",
    "NODES=4\n",
    "\n",
    "random.seed(SEED)\n",
    "ENGINES = 248\n",
    "ids = [*range(1,ENGINES+1)]\n",
    "random.shuffle(ids)\n",
    "training_ids = ids[:int(len(ids)*VAL_PERCENTAGE)] \n",
    "validation_ids = ids[int(len(ids)*VAL_PERCENTAGE):int(len(ids))]\n",
    " \n",
    "#IDS_NODES_TRAIN=[training_ids[x:x+(len(training_ids)+1)//NODES] for x in range(0, len(training_ids)+1, (len(training_ids)+1)//NODES)]\n",
    "#IDS_NODES_TEST=[validation_ids[x:x+(len(validation_ids)+1)//NODES] for x in range(0, len(validation_ids)+1, (len(validation_ids)+1)//NODES)]\n",
    "        \n",
    "IDS_NODES_TRAIN=[ids[:int(len(ids)*VAL_PERCENTAGE)],ids[:int(len(ids)*VAL_PERCENTAGE)],ids[:int(len(ids)*VAL_PERCENTAGE)],ids[:int(len(ids)*VAL_PERCENTAGE)]]\n",
    "IDS_NODES_TEST=[ids[int(len(ids)*VAL_PERCENTAGE):int(len(ids))],ids[int(len(ids)*VAL_PERCENTAGE):int(len(ids))],ids[int(len(ids)*VAL_PERCENTAGE):int(len(ids))],ids[int(len(ids)*VAL_PERCENTAGE):int(len(ids))]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35af2801",
   "metadata": {},
   "source": [
    "## Split data and send Labels to Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b0ccd70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_LABELS=[*range(0,NODES)]\n",
    "MAX_DATASET_SIZE=0\n",
    "\n",
    "for node in range(0,NODES):\n",
    "    data_node = IDS_NODES_TRAIN[node]\n",
    "    #random.shuffle(SEQUENCE_COLS)\n",
    "    sequence_cols_ = SEQUENCE_COLS[:int(len(SEQUENCE_COLS)*FEATURES_PERCENTAGE)]\n",
    "                \n",
    "    for x in range(len(data_node)):\n",
    "        data_trajectory = train_df.loc[train_df['id'] == data_node[x]]\n",
    "        # Get X and Y data\n",
    "        if x == 0:\n",
    "            _train=data_trajectory[sequence_cols_]\n",
    "        if x != 0:\n",
    "            _train=_train.append(data_trajectory[sequence_cols_],ignore_index=True)\n",
    "        if x == len(data_node)-1:\n",
    "            _train=_train.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "            X_train=_train[SENSOR_COLS]\n",
    "            y_train=_train[TARGET_COLS]\n",
    "            M_LABELS[node]=np.round(y_train.to_numpy(), 3).tolist()\n",
    "            if (MAX_DATASET_SIZE<y_train.to_numpy().size):\n",
    "                MAX_DATASET_SIZE=y_train.to_numpy().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "34a2b823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51641, 4)\n"
     ]
    }
   ],
   "source": [
    "M=np.empty((MAX_DATASET_SIZE,NODES))\n",
    "print(M.shape)\n",
    "M[:] = np.nan\n",
    "for x in range(0,NODES):\n",
    "    M[:len(M_LABELS[x]),x]=list(chain.from_iterable(M_LABELS[x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf2eee4",
   "metadata": {},
   "source": [
    "# Calculaling Label Matrix for first Lab (node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "296eb555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "def labelSynchronization(M, localLab):\n",
    "    numWorkers = len(list(zip(*M)))\n",
    "    ID=list(np.unique(M[:,0]))\n",
    "    synchronizedLabels=np.zeros(M.shape,dtype=int)\n",
    "    synchronizedLabels[:,localLab]=range(1,len(M)+1);\n",
    "    if(numWorkers>1):\n",
    "        labelsAndCounters=np.zeros((len(ID),numWorkers))\n",
    "        for worker in range(0,numWorkers):\n",
    "            for _id in range(0,len(ID)):\n",
    "                labelsAndCounters[_id,worker]=operator.countOf(M[:,worker].tolist(),ID[_id])\n",
    "        for worker in range(0,numWorkers):\n",
    "            if worker!=localLab:\n",
    "                counterPerLabel=np.zeros((len(ID),numWorkers), dtype=int)\n",
    "                for _id in range(0, len(ID)):\n",
    "                    element=np.where(M[:, worker]== ID[_id])\n",
    "                    for row in range(0, len(M)):\n",
    "                        if (M[row,localLab]== ID[_id]):\n",
    "                            synchronizedLabels[row,worker]=(list(element)[0])[counterPerLabel[_id,numWorkers-1]]+1\n",
    "                            counterPerLabel[_id,numWorkers-1] += 1\n",
    "                            if counterPerLabel[_id,numWorkers-1]>len(element):\n",
    "                                counterPerLabel[_id,numWorkers-1]=1\n",
    "    return synchronizedLabels\n",
    "\n",
    "\n",
    "SYNCHRONIZED_LABELS=labelSynchronization(M, 0)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "166a53b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0,     0],\n",
       "       [    1,     1,     1,     1],\n",
       "       [    2,     2,     2,     2],\n",
       "       ...,\n",
       "       [51638,     1,     1,     1],\n",
       "       [51639,  1256,  1256,  1256],\n",
       "       [51640,     1,     1,     1]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SYNCHRONIZED_LABELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6782b2cd",
   "metadata": {},
   "source": [
    "## Setup input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "51804a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_h5_file(resources_path, name):\n",
    "    # Read numpy array \n",
    "    hf = h5py.File(resources_path+name+\"-centralized.h5\", 'r')\n",
    "    return np.array(hf[name][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7cee6dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [0,1,2,3] \n",
    "model = \"mlp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4283c604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data(test, batch_size):\n",
    "    m,n = test.shape\n",
    "    S = test.itemsize\n",
    "    if not batch_size:\n",
    "        batch_size = m\n",
    "    count_batches = m//batch_size\n",
    "    # Batches which can be covered fully\n",
    "    test_batches = as_strided(test, shape=(count_batches, batch_size, n), strides=(batch_size*n*S,n*S,S)).copy()\n",
    "    covered = count_batches*batch_size\n",
    "    if covered < m:\n",
    "        rest = test[covered:,:]\n",
    "        rm, rn = rest.shape\n",
    "        mismatch = batch_size - rm\n",
    "        last_batch = np.vstack((rest,np.zeros((mismatch,rn)))).reshape(1,-1,n)\n",
    "        return np.vstack((test_batches,last_batch))\n",
    "    return test_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ee9a5832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_data_partition(df,IDS_NODES,test):\n",
    "    distributedData=[]\n",
    "    for replica in range(0, NODES):\n",
    "        DATA_REPLICA_ID = []\n",
    "        for data_node in IDS_NODES:\n",
    "            routes_ = {}\n",
    "            random.shuffle(SEQUENCE_COLS)\n",
    "            sequence_cols_ = SEQUENCE_COLS[:int(len(SEQUENCE_COLS)*FEATURES_PERCENTAGE)]\n",
    "            _ids = ids[:int(len(data_node))] \n",
    "            for x in range(len(_ids)):\n",
    "                data_trajectory = df.loc[df['id'] == _ids[x]]\n",
    "                # Get X and Y data\n",
    "                if x == 0:\n",
    "                    _data=data_trajectory[SEQUENCE_COLS] \n",
    "                if x != 0:\n",
    "                    _data=_data.append(data_trajectory[SEQUENCE_COLS],ignore_index=True)\n",
    "                if x == len(_ids)-1:\n",
    "                    _data=_data.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "        X_=_data[SENSOR_COLS].to_numpy()\n",
    "        y_=_data[TARGET_COLS].to_numpy()\n",
    "        if (test==False):\n",
    "            X_=X_[SYNCHRONIZED_LABELS[:,replica]][:,:]\n",
    "            y_=y_[SYNCHRONIZED_LABELS[:,replica]][:,:]\n",
    "        \n",
    "        X_=batch_data(X_,BATCH_SIZE)\n",
    "        y_=batch_data(y_,BATCH_SIZE)\n",
    "        for i in range(0,len(y_)):\n",
    "            DATA_REPLICA_ID.append((tf.convert_to_tensor(X_[i], dtype=tf.float32),tf.convert_to_tensor(y_[i], dtype=tf.float32)))\n",
    "        distributedData.append(DATA_REPLICA_ID)\n",
    "    return distributedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a6d20126",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pq.read_table(OUT_PATH + 'train_fd00' + str(NUMBER_OF_DATASET)+'.parquet').to_pandas()\n",
    "distributedDataTrain = fn_data_partition(train_df,IDS_NODES_TRAIN, False)\n",
    "distributedDataTest = fn_data_partition(train_df,IDS_NODES_TEST, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0a1cf987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_fn_train(ctx):\n",
    "    return distributedDataTrain[ctx.replica_id_in_sync_group]\n",
    "def value_fn_test(ctx):\n",
    "    return distributedDataTrain[ctx.replica_id_in_sync_group]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c9a8a74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "distributed_values_train = strategy.experimental_distribute_values_from_function(value_fn_train)\n",
    "distributed_values_test = strategy.experimental_distribute_values_from_function(value_fn_test)\n",
    "\n",
    "local_result_train = strategy.experimental_local_results(distributed_values_train)[0]\n",
    "local_result_test = strategy.experimental_local_results(distributed_values_test)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627f2388",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "bfab9899",
   "metadata": {},
   "outputs": [],
   "source": [
    " def create_model_mlp(input_signals):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation=\"sigmoid\", input_shape=(input_signals,)))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    #model.compile(loss=rmse,optimizer=optimizer,metrics=['mae','mse',rmse])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "38dc7e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a checkpoint directory to store the checkpoints.\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36da8e1a",
   "metadata": {},
   "source": [
    "## Define the loss function\n",
    "\n",
    "Recall that the loss function consists of one or two parts:\n",
    "\n",
    "  * The **prediction loss** measures how far off the model's predictions are from the training labels for a batch of training examples. It is computed for each labeled example and then reduced across the batch by computing the average value.\n",
    "  * Optionally, **regularization loss** terms can be added to the prediction loss, to steer the model away from overfitting the training data. A common choice is L2 regularization, which adds a small fixed multiple of the sum of squares of all model weights, independent of the number of examples. The model above uses L2 regularization to demonstrate its handling in the training loop below.\n",
    "\n",
    "For training on a single machine with a single GPU/CPU, this works as follows:\n",
    "\n",
    "  * The prediction loss is computed for each example in the batch, summed across the batch, and then divided by the batch size.\n",
    "  * The regularization loss is added to the prediction loss.\n",
    "  * The gradient of the total loss is computed w.r.t. each model weight, and the optimizer updates each model weight from the corresponding gradient.\n",
    "\n",
    "With `tf.distribute.Strategy`, the input batch is split between replicas.\n",
    "For example, let's say you have 4 GPUs, each with one replica of the model. One batch of 256 input examples is distributed evenly across the 4 replicas, so each replica gets a batch of size 64: We have `256 = 4*64`, or generally `GLOBAL_BATCH_SIZE = num_replicas_in_sync * BATCH_SIZE_PER_REPLICA`.\n",
    "\n",
    "Each replica computes the loss from the training examples it gets and computes the gradients of the loss w.r.t. each model weight. The optimizer takes care that these **gradients are summed up across replicas** before using them to update the copies of the model weights on each replica.\n",
    "\n",
    "*So, how should the loss be calculated when using a `tf.distribute.Strategy`?*\n",
    "\n",
    "  * Each replica computes the prediction loss for all examples distributed to it, sums up the results and divides them by `num_replicas_in_sync * BATCH_SIZE_PER_REPLICA`, or equivently, `GLOBAL_BATCH_SIZE`.\n",
    "  * Each replica compues the regularization loss(es) and divides them by\n",
    "  `num_replicas_in_sync`.\n",
    "\n",
    "Compared to non-distributed training, all per-replica loss terms are scaled down by a factor of `1/num_replicas_in_sync`. On the other hand, all loss terms -- or rather, their gradients -- are summed across that number of replicas before the optimizer applies them. In effect, the optimizer on each replica uses the same gradients as if a non-distributed computation with `GLOBAL_BATCH_SIZE` had happened. This is consistent with the distributed and undistributed behavior of Keras `Model.fit`. See the [Distributed training with Keras](./keras.ipynb) tutorial on how a larger gloabl batch size enables to scale up the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "75dc4e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    def compute_loss_batch(labels, predictions, model_losses):\n",
    "        per_example_loss = (labels - predictions)**2  # Sample error\n",
    "        loss = tf.math.sqrt(tf.nn.compute_average_loss(per_example_loss)) # Batch Error\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "36fd9a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    test_mae = tf.keras.metrics.MeanAbsoluteError()\n",
    "    train_rmse = tf.keras.metrics.RootMeanSquaredError()\n",
    "    test_rmse = tf.keras.metrics.RootMeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "a68e1b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A model, an optimizer, and a checkpoint must be created under `strategy.scope`.\n",
    "with strategy.scope():\n",
    "    model = create_model_mlp(16)\n",
    "    optimizer = SGD(lr=LEARNING_RATE)\n",
    "    checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "4767aae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step_batch(inputs):\n",
    "    input_signals, labels = inputs\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(input_signals, training=True)\n",
    "        loss = compute_loss_batch(labels, predictions, model.losses) # Batch Error\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    train_rmse.update_state(labels, predictions)\n",
    "    return loss\n",
    "def train_step_sample(inputs):\n",
    "    input_signals, labels = inputs\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(input_signals, training=True)\n",
    "    return predictions\n",
    "\n",
    "def compute_loss_fedLabSync(inputs, collaborativePredictions):\n",
    "    input_signals, labels = inputs\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(input_signals, training=True)\n",
    "        loss = compute_loss_batch(labels, (collaborativePredictions+predictions)/2, model.losses) # Batch Error\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    train_rmse.update_state(labels, (collaborativePredictions+predictions)/2)\n",
    "    return loss\n",
    "    \n",
    "def test_step(inputs):\n",
    "    input_signals, labels = inputs\n",
    "    predictions = model(input_signals, training=False)\n",
    "    \n",
    "    t_loss = tf.math.abs(labels-predictions)\n",
    "    test_mae.update_state(labels, predictions)\n",
    "    test_rmse.update_state(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "6c97e375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train_RMSE: 0.2896575331687927, Test MAE: 0.1990937888622284, Test_RMSE: 0.24162410199642181\n",
      "Epoch 2, Train_RMSE: 0.23430991172790527, Test MAE: 0.18677197396755219, Test_RMSE: 0.22944457828998566\n",
      "Epoch 3, Train_RMSE: 0.2262091338634491, Test MAE: 0.18200354278087616, Test_RMSE: 0.22376202046871185\n",
      "Epoch 4, Train_RMSE: 0.22158987820148468, Test MAE: 0.17897269129753113, Test_RMSE: 0.21997052431106567\n",
      "Epoch 5, Train_RMSE: 0.21833057701587677, Test MAE: 0.17675194144248962, Test_RMSE: 0.2171596735715866\n",
      "Epoch 6, Train_RMSE: 0.21584652364253998, Test MAE: 0.17500805854797363, Test_RMSE: 0.21495948731899261\n",
      "Epoch 7, Train_RMSE: 0.21386830508708954, Test MAE: 0.17356808483600616, Test_RMSE: 0.21317614614963531\n",
      "Epoch 8, Train_RMSE: 0.2122470736503601, Test MAE: 0.17233848571777344, Test_RMSE: 0.21169735491275787\n",
      "Epoch 9, Train_RMSE: 0.21089135110378265, Test MAE: 0.1712726205587387, Test_RMSE: 0.21044936776161194\n",
      "Epoch 10, Train_RMSE: 0.20973818004131317, Test MAE: 0.17033231258392334, Test_RMSE: 0.20937861502170563\n",
      "Epoch 11, Train_RMSE: 0.20874138176441193, Test MAE: 0.16948191821575165, Test_RMSE: 0.20844516158103943\n",
      "Epoch 12, Train_RMSE: 0.20786546170711517, Test MAE: 0.16869917511940002, Test_RMSE: 0.207618847489357\n",
      "Epoch 13, Train_RMSE: 0.20708461105823517, Test MAE: 0.16796396672725677, Test_RMSE: 0.2068755030632019\n",
      "Epoch 14, Train_RMSE: 0.20637834072113037, Test MAE: 0.16726882755756378, Test_RMSE: 0.20619867742061615\n",
      "Epoch 15, Train_RMSE: 0.20573115348815918, Test MAE: 0.1666092425584793, Test_RMSE: 0.2055746614933014\n",
      "Epoch 16, Train_RMSE: 0.20513005554676056, Test MAE: 0.16596867144107819, Test_RMSE: 0.2049909085035324\n",
      "Epoch 17, Train_RMSE: 0.20456618070602417, Test MAE: 0.16534735262393951, Test_RMSE: 0.20444421470165253\n",
      "Epoch 18, Train_RMSE: 0.20403249561786652, Test MAE: 0.1647367626428604, Test_RMSE: 0.20392227172851562\n",
      "Epoch 19, Train_RMSE: 0.20352350175380707, Test MAE: 0.16413308680057526, Test_RMSE: 0.20342208445072174\n",
      "Epoch 20, Train_RMSE: 0.20303380489349365, Test MAE: 0.16353937983512878, Test_RMSE: 0.2029396891593933\n",
      "Epoch 21, Train_RMSE: 0.20255984365940094, Test MAE: 0.16295091807842255, Test_RMSE: 0.2024715393781662\n",
      "Epoch 22, Train_RMSE: 0.20209835469722748, Test MAE: 0.1623711735010147, Test_RMSE: 0.20201769471168518\n",
      "Epoch 23, Train_RMSE: 0.20164762437343597, Test MAE: 0.16178935766220093, Test_RMSE: 0.201571524143219\n",
      "Epoch 24, Train_RMSE: 0.2012060433626175, Test MAE: 0.16120916604995728, Test_RMSE: 0.20113344490528107\n",
      "Epoch 25, Train_RMSE: 0.20077207684516907, Test MAE: 0.160630002617836, Test_RMSE: 0.20070253312587738\n",
      "Epoch 26, Train_RMSE: 0.20034469664096832, Test MAE: 0.16005189716815948, Test_RMSE: 0.20028021931648254\n",
      "Epoch 27, Train_RMSE: 0.1999230980873108, Test MAE: 0.1594703197479248, Test_RMSE: 0.19986113905906677\n",
      "Epoch 28, Train_RMSE: 0.19950687885284424, Test MAE: 0.15888963639736176, Test_RMSE: 0.19944743812084198\n",
      "Epoch 29, Train_RMSE: 0.19909609854221344, Test MAE: 0.15830788016319275, Test_RMSE: 0.19903816282749176\n",
      "Epoch 30, Train_RMSE: 0.19868974387645721, Test MAE: 0.15772326290607452, Test_RMSE: 0.19863161444664001\n",
      "Epoch 31, Train_RMSE: 0.19828832149505615, Test MAE: 0.15714646875858307, Test_RMSE: 0.1982330083847046\n",
      "Epoch 32, Train_RMSE: 0.19789239764213562, Test MAE: 0.1565753072500229, Test_RMSE: 0.19784103333950043\n",
      "Epoch 33, Train_RMSE: 0.19750253856182098, Test MAE: 0.15600712597370148, Test_RMSE: 0.19745445251464844\n",
      "Epoch 34, Train_RMSE: 0.19711852073669434, Test MAE: 0.15544746816158295, Test_RMSE: 0.19707371294498444\n",
      "Epoch 35, Train_RMSE: 0.1967409998178482, Test MAE: 0.1548966020345688, Test_RMSE: 0.1966995745897293\n",
      "Epoch 36, Train_RMSE: 0.19637000560760498, Test MAE: 0.1543576419353485, Test_RMSE: 0.19633223116397858\n",
      "Epoch 37, Train_RMSE: 0.19600622355937958, Test MAE: 0.15382778644561768, Test_RMSE: 0.19597162306308746\n",
      "Epoch 38, Train_RMSE: 0.19564928114414215, Test MAE: 0.1533166915178299, Test_RMSE: 0.1956186145544052\n",
      "Epoch 39, Train_RMSE: 0.19530008733272552, Test MAE: 0.15282155573368073, Test_RMSE: 0.19527335464954376\n",
      "Epoch 40, Train_RMSE: 0.19495847821235657, Test MAE: 0.15234561264514923, Test_RMSE: 0.19493597745895386\n",
      "Epoch 41, Train_RMSE: 0.19462503492832184, Test MAE: 0.15188822150230408, Test_RMSE: 0.19460663199424744\n",
      "Epoch 42, Train_RMSE: 0.19429980218410492, Test MAE: 0.1514504998922348, Test_RMSE: 0.19428537786006927\n",
      "Epoch 43, Train_RMSE: 0.19398260116577148, Test MAE: 0.15102986991405487, Test_RMSE: 0.19397203624248505\n",
      "Epoch 44, Train_RMSE: 0.19367365539073944, Test MAE: 0.15062610805034637, Test_RMSE: 0.19366750121116638\n",
      "Epoch 45, Train_RMSE: 0.19337287545204163, Test MAE: 0.15023745596408844, Test_RMSE: 0.19337166845798492\n",
      "Epoch 46, Train_RMSE: 0.19308048486709595, Test MAE: 0.14986379444599152, Test_RMSE: 0.19308409094810486\n",
      "Epoch 47, Train_RMSE: 0.1927964687347412, Test MAE: 0.14950217306613922, Test_RMSE: 0.19280453026294708\n",
      "Epoch 48, Train_RMSE: 0.19252066314220428, Test MAE: 0.1491548717021942, Test_RMSE: 0.19253304600715637\n",
      "Epoch 49, Train_RMSE: 0.19225278496742249, Test MAE: 0.14881931245326996, Test_RMSE: 0.19226911664009094\n",
      "Epoch 50, Train_RMSE: 0.1919926553964615, Test MAE: 0.14849619567394257, Test_RMSE: 0.19201263785362244\n",
      "Epoch 51, Train_RMSE: 0.19173994660377502, Test MAE: 0.148187056183815, Test_RMSE: 0.19176402688026428\n",
      "Epoch 52, Train_RMSE: 0.19149455428123474, Test MAE: 0.14788351953029633, Test_RMSE: 0.19152164459228516\n",
      "Epoch 53, Train_RMSE: 0.19125591218471527, Test MAE: 0.14759217202663422, Test_RMSE: 0.19128745794296265\n",
      "Epoch 54, Train_RMSE: 0.191023588180542, Test MAE: 0.14730550348758698, Test_RMSE: 0.1910601705312729\n",
      "Epoch 55, Train_RMSE: 0.19079773128032684, Test MAE: 0.1470276266336441, Test_RMSE: 0.19083769619464874\n",
      "Epoch 56, Train_RMSE: 0.19057804346084595, Test MAE: 0.1467590481042862, Test_RMSE: 0.19062180817127228\n",
      "Epoch 57, Train_RMSE: 0.1903647631406784, Test MAE: 0.14649750292301178, Test_RMSE: 0.19041140377521515\n",
      "Epoch 58, Train_RMSE: 0.19015702605247498, Test MAE: 0.1462409794330597, Test_RMSE: 0.19020506739616394\n",
      "Epoch 59, Train_RMSE: 0.1899546980857849, Test MAE: 0.1459912359714508, Test_RMSE: 0.19000522792339325\n",
      "Epoch 60, Train_RMSE: 0.18975721299648285, Test MAE: 0.14574621617794037, Test_RMSE: 0.18981018662452698\n",
      "Epoch 61, Train_RMSE: 0.18956458568572998, Test MAE: 0.14550891518592834, Test_RMSE: 0.1896202564239502\n",
      "Epoch 62, Train_RMSE: 0.18937702476978302, Test MAE: 0.14527496695518494, Test_RMSE: 0.18943263590335846\n",
      "Epoch 63, Train_RMSE: 0.18919318914413452, Test MAE: 0.14504803717136383, Test_RMSE: 0.18925148248672485\n",
      "Epoch 64, Train_RMSE: 0.1890135556459427, Test MAE: 0.14482548832893372, Test_RMSE: 0.18907441198825836\n",
      "Epoch 65, Train_RMSE: 0.1888371706008911, Test MAE: 0.14460717141628265, Test_RMSE: 0.18890079855918884\n",
      "Epoch 66, Train_RMSE: 0.18866486847400665, Test MAE: 0.1443907618522644, Test_RMSE: 0.18873056769371033\n",
      "Epoch 67, Train_RMSE: 0.18849626183509827, Test MAE: 0.14417590200901031, Test_RMSE: 0.18856243789196014\n",
      "Epoch 68, Train_RMSE: 0.18833057582378387, Test MAE: 0.14396555721759796, Test_RMSE: 0.188397616147995\n",
      "Epoch 69, Train_RMSE: 0.1881675124168396, Test MAE: 0.1437605917453766, Test_RMSE: 0.18823516368865967\n",
      "Epoch 70, Train_RMSE: 0.18800659477710724, Test MAE: 0.14355501532554626, Test_RMSE: 0.18807515501976013\n",
      "Epoch 71, Train_RMSE: 0.18784844875335693, Test MAE: 0.1433480978012085, Test_RMSE: 0.18791529536247253\n",
      "Epoch 72, Train_RMSE: 0.18769261240959167, Test MAE: 0.1431504189968109, Test_RMSE: 0.18776027858257294\n",
      "Epoch 73, Train_RMSE: 0.18753932416439056, Test MAE: 0.14295688271522522, Test_RMSE: 0.18760764598846436\n",
      "Epoch 74, Train_RMSE: 0.1873885989189148, Test MAE: 0.14276547729969025, Test_RMSE: 0.18745745718479156\n",
      "Epoch 75, Train_RMSE: 0.18724022805690765, Test MAE: 0.1425779014825821, Test_RMSE: 0.18730959296226501\n",
      "Epoch 76, Train_RMSE: 0.18709424138069153, Test MAE: 0.14239132404327393, Test_RMSE: 0.18716365098953247\n",
      "Epoch 77, Train_RMSE: 0.18695005774497986, Test MAE: 0.14220952987670898, Test_RMSE: 0.18701978027820587\n",
      "Epoch 78, Train_RMSE: 0.18680796027183533, Test MAE: 0.142030730843544, Test_RMSE: 0.18687811493873596\n",
      "Epoch 79, Train_RMSE: 0.1866680085659027, Test MAE: 0.14185376465320587, Test_RMSE: 0.18673832714557648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, Train_RMSE: 0.18652991950511932, Test MAE: 0.14168138802051544, Test_RMSE: 0.18660052120685577\n",
      "Epoch 81, Train_RMSE: 0.18639349937438965, Test MAE: 0.14151357114315033, Test_RMSE: 0.18646547198295593\n",
      "Epoch 82, Train_RMSE: 0.1862586885690689, Test MAE: 0.14135150611400604, Test_RMSE: 0.18633297085762024\n",
      "Epoch 83, Train_RMSE: 0.18612585961818695, Test MAE: 0.14118705689907074, Test_RMSE: 0.1862003654241562\n",
      "Epoch 84, Train_RMSE: 0.1859944611787796, Test MAE: 0.14102225005626678, Test_RMSE: 0.1860693097114563\n",
      "Epoch 85, Train_RMSE: 0.18586470186710358, Test MAE: 0.14086201786994934, Test_RMSE: 0.18593978881835938\n",
      "Epoch 86, Train_RMSE: 0.18573661148548126, Test MAE: 0.14070282876491547, Test_RMSE: 0.18581180274486542\n",
      "Epoch 87, Train_RMSE: 0.18560989201068878, Test MAE: 0.14054761826992035, Test_RMSE: 0.1856852024793625\n",
      "Epoch 88, Train_RMSE: 0.18548458814620972, Test MAE: 0.14039510488510132, Test_RMSE: 0.18556001782417297\n",
      "Epoch 89, Train_RMSE: 0.1853606402873993, Test MAE: 0.1402451992034912, Test_RMSE: 0.18543648719787598\n",
      "Epoch 90, Train_RMSE: 0.18523800373077393, Test MAE: 0.14009544253349304, Test_RMSE: 0.18531396985054016\n",
      "Epoch 91, Train_RMSE: 0.18511666357517242, Test MAE: 0.13994725048542023, Test_RMSE: 0.18519268929958344\n",
      "Epoch 92, Train_RMSE: 0.18499666452407837, Test MAE: 0.13979990780353546, Test_RMSE: 0.18507245182991028\n",
      "Epoch 93, Train_RMSE: 0.18487748503684998, Test MAE: 0.13965484499931335, Test_RMSE: 0.18495337665081024\n",
      "Epoch 94, Train_RMSE: 0.18475967645645142, Test MAE: 0.13951124250888824, Test_RMSE: 0.1848354935646057\n",
      "Epoch 95, Train_RMSE: 0.1846425086259842, Test MAE: 0.13937224447727203, Test_RMSE: 0.18471971154212952\n",
      "Epoch 96, Train_RMSE: 0.1845264881849289, Test MAE: 0.13923199474811554, Test_RMSE: 0.18460384011268616\n",
      "Epoch 97, Train_RMSE: 0.1844114363193512, Test MAE: 0.13909393548965454, Test_RMSE: 0.18448884785175323\n",
      "Epoch 98, Train_RMSE: 0.1842973530292511, Test MAE: 0.13895951211452484, Test_RMSE: 0.18437543511390686\n",
      "Epoch 99, Train_RMSE: 0.184184268116951, Test MAE: 0.13882435858249664, Test_RMSE: 0.18426232039928436\n",
      "Epoch 100, Train_RMSE: 0.18407247960567474, Test MAE: 0.1386876106262207, Test_RMSE: 0.1841495782136917\n",
      "Epoch 101, Train_RMSE: 0.18396079540252686, Test MAE: 0.13855406641960144, Test_RMSE: 0.1840376853942871\n",
      "Epoch 102, Train_RMSE: 0.18384955823421478, Test MAE: 0.13843029737472534, Test_RMSE: 0.18392905592918396\n",
      "Epoch 103, Train_RMSE: 0.1837390810251236, Test MAE: 0.13830068707466125, Test_RMSE: 0.18381904065608978\n",
      "Epoch 104, Train_RMSE: 0.18362955749034882, Test MAE: 0.13817258179187775, Test_RMSE: 0.183709517121315\n",
      "Epoch 105, Train_RMSE: 0.1835208237171173, Test MAE: 0.13804525136947632, Test_RMSE: 0.1836007982492447\n",
      "Epoch 106, Train_RMSE: 0.18341262638568878, Test MAE: 0.13791871070861816, Test_RMSE: 0.1834927201271057\n",
      "Epoch 107, Train_RMSE: 0.18330512940883636, Test MAE: 0.13779322803020477, Test_RMSE: 0.18338555097579956\n",
      "Epoch 108, Train_RMSE: 0.18319815397262573, Test MAE: 0.13767094910144806, Test_RMSE: 0.1832786649465561\n",
      "Epoch 109, Train_RMSE: 0.1830919235944748, Test MAE: 0.1375504434108734, Test_RMSE: 0.1831725537776947\n",
      "Epoch 110, Train_RMSE: 0.1829860806465149, Test MAE: 0.13742861151695251, Test_RMSE: 0.18306678533554077\n",
      "Epoch 111, Train_RMSE: 0.18288077414035797, Test MAE: 0.13730956614017487, Test_RMSE: 0.18296153843402863\n",
      "Epoch 112, Train_RMSE: 0.18277636170387268, Test MAE: 0.13719168305397034, Test_RMSE: 0.18285690248012543\n",
      "Epoch 113, Train_RMSE: 0.18267212808132172, Test MAE: 0.13707131147384644, Test_RMSE: 0.18275263905525208\n",
      "Epoch 114, Train_RMSE: 0.18256838619709015, Test MAE: 0.1369524449110031, Test_RMSE: 0.18264883756637573\n",
      "Epoch 115, Train_RMSE: 0.1824645698070526, Test MAE: 0.13683417439460754, Test_RMSE: 0.1825454831123352\n",
      "Epoch 116, Train_RMSE: 0.18236131966114044, Test MAE: 0.13671883940696716, Test_RMSE: 0.18244250118732452\n",
      "Epoch 117, Train_RMSE: 0.18225863575935364, Test MAE: 0.13660502433776855, Test_RMSE: 0.18233990669250488\n",
      "Epoch 118, Train_RMSE: 0.18215638399124146, Test MAE: 0.13649064302444458, Test_RMSE: 0.18223722279071808\n",
      "Epoch 119, Train_RMSE: 0.18205446004867554, Test MAE: 0.13638079166412354, Test_RMSE: 0.1821354180574417\n",
      "Epoch 120, Train_RMSE: 0.18195311725139618, Test MAE: 0.13626696169376373, Test_RMSE: 0.1820336878299713\n",
      "Epoch 121, Train_RMSE: 0.1818518340587616, Test MAE: 0.13615432381629944, Test_RMSE: 0.18193240463733673\n",
      "Epoch 122, Train_RMSE: 0.1817508041858673, Test MAE: 0.13604584336280823, Test_RMSE: 0.1818317174911499\n",
      "Epoch 123, Train_RMSE: 0.18165016174316406, Test MAE: 0.13593783974647522, Test_RMSE: 0.18173128366470337\n",
      "Epoch 124, Train_RMSE: 0.1815498322248459, Test MAE: 0.1358311027288437, Test_RMSE: 0.18163152039051056\n",
      "Epoch 125, Train_RMSE: 0.18144991993904114, Test MAE: 0.13572490215301514, Test_RMSE: 0.1815319061279297\n",
      "Epoch 126, Train_RMSE: 0.18135017156600952, Test MAE: 0.13562177121639252, Test_RMSE: 0.1814325898885727\n",
      "Epoch 127, Train_RMSE: 0.18125076591968536, Test MAE: 0.13551628589630127, Test_RMSE: 0.1813335418701172\n",
      "Epoch 128, Train_RMSE: 0.18115191161632538, Test MAE: 0.13541065156459808, Test_RMSE: 0.18123480677604675\n",
      "Epoch 129, Train_RMSE: 0.18105320632457733, Test MAE: 0.13530580699443817, Test_RMSE: 0.18113656342029572\n",
      "Epoch 130, Train_RMSE: 0.18095460534095764, Test MAE: 0.13520073890686035, Test_RMSE: 0.18103830516338348\n",
      "Epoch 131, Train_RMSE: 0.18085640668869019, Test MAE: 0.13509882986545563, Test_RMSE: 0.1809404343366623\n",
      "Epoch 132, Train_RMSE: 0.18075843155384064, Test MAE: 0.13499948382377625, Test_RMSE: 0.18084318935871124\n",
      "Epoch 133, Train_RMSE: 0.18066100776195526, Test MAE: 0.1348995417356491, Test_RMSE: 0.18074606359004974\n",
      "Epoch 134, Train_RMSE: 0.18056383728981018, Test MAE: 0.13480038940906525, Test_RMSE: 0.18064939975738525\n",
      "Epoch 135, Train_RMSE: 0.18046700954437256, Test MAE: 0.13470503687858582, Test_RMSE: 0.18055348098278046\n",
      "Epoch 136, Train_RMSE: 0.18037021160125732, Test MAE: 0.13460814952850342, Test_RMSE: 0.18045742809772491\n",
      "Epoch 137, Train_RMSE: 0.18027395009994507, Test MAE: 0.13451290130615234, Test_RMSE: 0.18036188185214996\n",
      "Epoch 138, Train_RMSE: 0.18017816543579102, Test MAE: 0.13441886007785797, Test_RMSE: 0.1802666038274765\n",
      "Epoch 139, Train_RMSE: 0.18008220195770264, Test MAE: 0.13432788848876953, Test_RMSE: 0.1801716536283493\n",
      "Epoch 140, Train_RMSE: 0.17998698353767395, Test MAE: 0.13423840701580048, Test_RMSE: 0.18007710576057434\n",
      "Epoch 141, Train_RMSE: 0.17989178001880646, Test MAE: 0.13414819538593292, Test_RMSE: 0.17998291552066803\n",
      "Epoch 142, Train_RMSE: 0.1797972470521927, Test MAE: 0.13405832648277283, Test_RMSE: 0.17988909780979156\n",
      "Epoch 143, Train_RMSE: 0.1797032654285431, Test MAE: 0.13397014141082764, Test_RMSE: 0.17979592084884644\n",
      "Epoch 144, Train_RMSE: 0.17960993945598602, Test MAE: 0.13388191163539886, Test_RMSE: 0.17970314621925354\n",
      "Epoch 145, Train_RMSE: 0.1795169860124588, Test MAE: 0.13379549980163574, Test_RMSE: 0.17961090803146362\n",
      "Epoch 146, Train_RMSE: 0.17942450940608978, Test MAE: 0.1337098777294159, Test_RMSE: 0.17951929569244385\n",
      "Epoch 147, Train_RMSE: 0.17933271825313568, Test MAE: 0.1336236149072647, Test_RMSE: 0.17942818999290466\n",
      "Epoch 148, Train_RMSE: 0.17924149334430695, Test MAE: 0.13354560732841492, Test_RMSE: 0.17933690547943115\n",
      "Epoch 149, Train_RMSE: 0.1791505664587021, Test MAE: 0.1334608644247055, Test_RMSE: 0.1792469173669815\n",
      "Epoch 150, Train_RMSE: 0.17906028032302856, Test MAE: 0.13337713479995728, Test_RMSE: 0.17915739119052887\n",
      "Epoch 151, Train_RMSE: 0.1789705902338028, Test MAE: 0.13329342007637024, Test_RMSE: 0.1790686696767807\n",
      "Epoch 152, Train_RMSE: 0.1788814514875412, Test MAE: 0.1332116425037384, Test_RMSE: 0.17898055911064148\n",
      "Epoch 153, Train_RMSE: 0.17879284918308258, Test MAE: 0.13313038647174835, Test_RMSE: 0.17889387905597687\n",
      "Epoch 154, Train_RMSE: 0.17870524525642395, Test MAE: 0.13304857909679413, Test_RMSE: 0.17880728840827942\n",
      "Epoch 155, Train_RMSE: 0.17861835658550262, Test MAE: 0.13296891748905182, Test_RMSE: 0.1787215769290924\n",
      "Epoch 156, Train_RMSE: 0.17853230237960815, Test MAE: 0.13288848102092743, Test_RMSE: 0.17863652110099792\n",
      "Epoch 157, Train_RMSE: 0.17844706773757935, Test MAE: 0.13281004130840302, Test_RMSE: 0.17855215072631836\n",
      "Epoch 158, Train_RMSE: 0.17836260795593262, Test MAE: 0.1327304244041443, Test_RMSE: 0.1784684807062149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159, Train_RMSE: 0.17827896773815155, Test MAE: 0.13265156745910645, Test_RMSE: 0.17838507890701294\n",
      "Epoch 160, Train_RMSE: 0.17819593846797943, Test MAE: 0.13257497549057007, Test_RMSE: 0.1783032864332199\n",
      "Epoch 161, Train_RMSE: 0.17811386287212372, Test MAE: 0.13249655067920685, Test_RMSE: 0.17822222411632538\n",
      "Epoch 162, Train_RMSE: 0.17803265154361725, Test MAE: 0.1324177384376526, Test_RMSE: 0.1781420111656189\n",
      "Epoch 163, Train_RMSE: 0.177952378988266, Test MAE: 0.13234111666679382, Test_RMSE: 0.17806264758110046\n",
      "Epoch 164, Train_RMSE: 0.17787308990955353, Test MAE: 0.13226404786109924, Test_RMSE: 0.1779841184616089\n",
      "Epoch 165, Train_RMSE: 0.17779456079006195, Test MAE: 0.13218912482261658, Test_RMSE: 0.17790618538856506\n",
      "Epoch 166, Train_RMSE: 0.17771655321121216, Test MAE: 0.13211411237716675, Test_RMSE: 0.17782916128635406\n",
      "Epoch 167, Train_RMSE: 0.1776396632194519, Test MAE: 0.13203848898410797, Test_RMSE: 0.1777530014514923\n",
      "Epoch 168, Train_RMSE: 0.17756380140781403, Test MAE: 0.1319621056318283, Test_RMSE: 0.17767782509326935\n",
      "Epoch 169, Train_RMSE: 0.1774888038635254, Test MAE: 0.13188862800598145, Test_RMSE: 0.17760346829891205\n",
      "Epoch 170, Train_RMSE: 0.177414670586586, Test MAE: 0.1318160444498062, Test_RMSE: 0.17753012478351593\n",
      "Epoch 171, Train_RMSE: 0.17734134197235107, Test MAE: 0.13174857199192047, Test_RMSE: 0.17745916545391083\n",
      "Epoch 172, Train_RMSE: 0.17726917564868927, Test MAE: 0.1316770613193512, Test_RMSE: 0.1773875504732132\n",
      "Epoch 173, Train_RMSE: 0.1771979033946991, Test MAE: 0.13160613179206848, Test_RMSE: 0.17731690406799316\n",
      "Epoch 174, Train_RMSE: 0.1771276444196701, Test MAE: 0.13153286278247833, Test_RMSE: 0.17724695801734924\n",
      "Epoch 175, Train_RMSE: 0.1770581752061844, Test MAE: 0.1314573436975479, Test_RMSE: 0.17717775702476501\n",
      "Epoch 176, Train_RMSE: 0.17698954045772552, Test MAE: 0.13138359785079956, Test_RMSE: 0.1771082580089569\n",
      "Epoch 177, Train_RMSE: 0.17692163586616516, Test MAE: 0.13131411373615265, Test_RMSE: 0.1770409345626831\n",
      "Epoch 178, Train_RMSE: 0.17685441672801971, Test MAE: 0.13124632835388184, Test_RMSE: 0.17697453498840332\n",
      "Epoch 179, Train_RMSE: 0.1767883002758026, Test MAE: 0.13118232786655426, Test_RMSE: 0.17690888047218323\n",
      "Epoch 180, Train_RMSE: 0.17672282457351685, Test MAE: 0.13111688196659088, Test_RMSE: 0.17684398591518402\n",
      "Epoch 181, Train_RMSE: 0.1766577512025833, Test MAE: 0.13105374574661255, Test_RMSE: 0.17677991092205048\n",
      "Epoch 182, Train_RMSE: 0.17659391462802887, Test MAE: 0.1309901475906372, Test_RMSE: 0.17671671509742737\n",
      "Epoch 183, Train_RMSE: 0.17653056979179382, Test MAE: 0.1309276670217514, Test_RMSE: 0.17665429413318634\n",
      "Epoch 184, Train_RMSE: 0.1764685958623886, Test MAE: 0.13085781037807465, Test_RMSE: 0.17659057676792145\n",
      "Epoch 185, Train_RMSE: 0.17640703916549683, Test MAE: 0.13079464435577393, Test_RMSE: 0.1765296310186386\n",
      "Epoch 186, Train_RMSE: 0.1763460636138916, Test MAE: 0.13073405623435974, Test_RMSE: 0.1764695793390274\n",
      "Epoch 187, Train_RMSE: 0.17628604173660278, Test MAE: 0.13067100942134857, Test_RMSE: 0.17641015350818634\n",
      "Epoch 188, Train_RMSE: 0.17622706294059753, Test MAE: 0.13060954213142395, Test_RMSE: 0.1763504147529602\n",
      "Epoch 189, Train_RMSE: 0.176168754696846, Test MAE: 0.13056954741477966, Test_RMSE: 0.17629215121269226\n",
      "Epoch 190, Train_RMSE: 0.1761103868484497, Test MAE: 0.13051514327526093, Test_RMSE: 0.17623481154441833\n",
      "Epoch 191, Train_RMSE: 0.17605283856391907, Test MAE: 0.13045598566532135, Test_RMSE: 0.1761779934167862\n",
      "Epoch 192, Train_RMSE: 0.17599596083164215, Test MAE: 0.13039766252040863, Test_RMSE: 0.176121786236763\n",
      "Epoch 193, Train_RMSE: 0.17593970894813538, Test MAE: 0.1303403377532959, Test_RMSE: 0.17606619000434875\n",
      "Epoch 194, Train_RMSE: 0.17588405311107635, Test MAE: 0.13028371334075928, Test_RMSE: 0.1760113388299942\n",
      "Epoch 195, Train_RMSE: 0.1758289933204651, Test MAE: 0.13022592663764954, Test_RMSE: 0.17595699429512024\n",
      "Epoch 196, Train_RMSE: 0.17577457427978516, Test MAE: 0.1301697939634323, Test_RMSE: 0.1759032905101776\n",
      "Epoch 197, Train_RMSE: 0.17572085559368134, Test MAE: 0.13011443614959717, Test_RMSE: 0.1758500188589096\n",
      "Epoch 198, Train_RMSE: 0.17566785216331482, Test MAE: 0.13006003201007843, Test_RMSE: 0.17579734325408936\n",
      "Epoch 199, Train_RMSE: 0.17561593651771545, Test MAE: 0.13000725209712982, Test_RMSE: 0.17574384808540344\n",
      "Epoch 200, Train_RMSE: 0.1755639761686325, Test MAE: 0.1299564391374588, Test_RMSE: 0.17569220066070557\n",
      "Epoch 201, Train_RMSE: 0.17551250755786896, Test MAE: 0.1299056112766266, Test_RMSE: 0.17564108967781067\n",
      "Epoch 202, Train_RMSE: 0.17546162009239197, Test MAE: 0.12985500693321228, Test_RMSE: 0.17559047043323517\n",
      "Epoch 203, Train_RMSE: 0.17541131377220154, Test MAE: 0.12980562448501587, Test_RMSE: 0.17554038763046265\n",
      "Epoch 204, Train_RMSE: 0.17536157369613647, Test MAE: 0.12975379824638367, Test_RMSE: 0.17549055814743042\n",
      "Epoch 205, Train_RMSE: 0.17531198263168335, Test MAE: 0.1297057569026947, Test_RMSE: 0.17544130980968475\n",
      "Epoch 206, Train_RMSE: 0.17526300251483917, Test MAE: 0.1296570599079132, Test_RMSE: 0.17539262771606445\n",
      "Epoch 207, Train_RMSE: 0.1752147227525711, Test MAE: 0.12961283326148987, Test_RMSE: 0.17534396052360535\n",
      "Epoch 208, Train_RMSE: 0.17516659200191498, Test MAE: 0.12956741452217102, Test_RMSE: 0.17529596388339996\n",
      "Epoch 209, Train_RMSE: 0.17511889338493347, Test MAE: 0.1295248568058014, Test_RMSE: 0.17524904012680054\n",
      "Epoch 210, Train_RMSE: 0.17507171630859375, Test MAE: 0.12948064506053925, Test_RMSE: 0.1752021461725235\n",
      "Epoch 211, Train_RMSE: 0.17502501606941223, Test MAE: 0.12943682074546814, Test_RMSE: 0.17515559494495392\n",
      "Epoch 212, Train_RMSE: 0.1749783158302307, Test MAE: 0.12939199805259705, Test_RMSE: 0.17510950565338135\n",
      "Epoch 213, Train_RMSE: 0.1749323308467865, Test MAE: 0.12935039401054382, Test_RMSE: 0.17506377398967743\n",
      "Epoch 214, Train_RMSE: 0.17488668859004974, Test MAE: 0.12930893898010254, Test_RMSE: 0.17501842975616455\n",
      "Epoch 215, Train_RMSE: 0.17484121024608612, Test MAE: 0.12927231192588806, Test_RMSE: 0.1749732792377472\n",
      "Epoch 216, Train_RMSE: 0.1747961789369583, Test MAE: 0.1292327344417572, Test_RMSE: 0.17492857575416565\n",
      "Epoch 217, Train_RMSE: 0.17475171387195587, Test MAE: 0.12919078767299652, Test_RMSE: 0.17488378286361694\n",
      "Epoch 218, Train_RMSE: 0.17470751702785492, Test MAE: 0.12914982438087463, Test_RMSE: 0.17483967542648315\n",
      "Epoch 219, Train_RMSE: 0.17466337978839874, Test MAE: 0.1291135549545288, Test_RMSE: 0.174796000123024\n",
      "Epoch 220, Train_RMSE: 0.17461977899074554, Test MAE: 0.12907230854034424, Test_RMSE: 0.17475159466266632\n",
      "Epoch 221, Train_RMSE: 0.17457634210586548, Test MAE: 0.12903515994548798, Test_RMSE: 0.17470863461494446\n",
      "Epoch 222, Train_RMSE: 0.17453332245349884, Test MAE: 0.12899848818778992, Test_RMSE: 0.17466586828231812\n",
      "Epoch 223, Train_RMSE: 0.17449060082435608, Test MAE: 0.12896211445331573, Test_RMSE: 0.17462344467639923\n",
      "Epoch 224, Train_RMSE: 0.17444837093353271, Test MAE: 0.12892554700374603, Test_RMSE: 0.1745813637971878\n",
      "Epoch 225, Train_RMSE: 0.17440566420555115, Test MAE: 0.12889337539672852, Test_RMSE: 0.174543097615242\n",
      "Epoch 226, Train_RMSE: 0.17436400055885315, Test MAE: 0.1288563311100006, Test_RMSE: 0.17450150847434998\n",
      "Epoch 227, Train_RMSE: 0.17432254552841187, Test MAE: 0.12882117927074432, Test_RMSE: 0.17446006834506989\n",
      "Epoch 228, Train_RMSE: 0.17428135871887207, Test MAE: 0.12878480553627014, Test_RMSE: 0.17441891133785248\n",
      "Epoch 229, Train_RMSE: 0.17423996329307556, Test MAE: 0.12876008450984955, Test_RMSE: 0.1743781417608261\n",
      "Epoch 230, Train_RMSE: 0.17419905960559845, Test MAE: 0.1287267506122589, Test_RMSE: 0.17433759570121765\n",
      "Epoch 231, Train_RMSE: 0.17415867745876312, Test MAE: 0.12869319319725037, Test_RMSE: 0.17429716885089874\n",
      "Epoch 232, Train_RMSE: 0.17411836981773376, Test MAE: 0.1286616325378418, Test_RMSE: 0.17425714433193207\n",
      "Epoch 233, Train_RMSE: 0.17407836019992828, Test MAE: 0.12862886488437653, Test_RMSE: 0.1742173135280609\n",
      "Epoch 234, Train_RMSE: 0.1740388125181198, Test MAE: 0.12859328091144562, Test_RMSE: 0.1741776019334793\n",
      "Epoch 235, Train_RMSE: 0.17399922013282776, Test MAE: 0.12856124341487885, Test_RMSE: 0.17413827776908875\n",
      "Epoch 236, Train_RMSE: 0.17395971715450287, Test MAE: 0.12852995097637177, Test_RMSE: 0.17409919202327728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237, Train_RMSE: 0.17392095923423767, Test MAE: 0.12849216163158417, Test_RMSE: 0.17405876517295837\n",
      "Epoch 238, Train_RMSE: 0.17388220131397247, Test MAE: 0.12845931947231293, Test_RMSE: 0.17401953041553497\n",
      "Epoch 239, Train_RMSE: 0.1738436371088028, Test MAE: 0.12842847406864166, Test_RMSE: 0.17398114502429962\n",
      "Epoch 240, Train_RMSE: 0.17380528151988983, Test MAE: 0.1283964067697525, Test_RMSE: 0.17394299805164337\n",
      "Epoch 241, Train_RMSE: 0.1737670749425888, Test MAE: 0.1283692717552185, Test_RMSE: 0.17390505969524384\n",
      "Epoch 242, Train_RMSE: 0.17372895777225494, Test MAE: 0.12833714485168457, Test_RMSE: 0.17386756837368011\n",
      "Epoch 243, Train_RMSE: 0.17369112372398376, Test MAE: 0.12830740213394165, Test_RMSE: 0.17383000254631042\n",
      "Epoch 244, Train_RMSE: 0.173653706908226, Test MAE: 0.12827813625335693, Test_RMSE: 0.17379267513751984\n",
      "Epoch 245, Train_RMSE: 0.173616424202919, Test MAE: 0.1282494068145752, Test_RMSE: 0.17375552654266357\n",
      "Epoch 246, Train_RMSE: 0.17357951402664185, Test MAE: 0.12822070717811584, Test_RMSE: 0.1737186759710312\n",
      "Epoch 247, Train_RMSE: 0.17354272305965424, Test MAE: 0.12819381058216095, Test_RMSE: 0.1736820489168167\n",
      "Epoch 248, Train_RMSE: 0.17350609600543976, Test MAE: 0.12816551327705383, Test_RMSE: 0.17364561557769775\n",
      "Epoch 249, Train_RMSE: 0.17346975207328796, Test MAE: 0.12813685834407806, Test_RMSE: 0.17360937595367432\n",
      "Epoch 250, Train_RMSE: 0.17343367636203766, Test MAE: 0.12810955941677094, Test_RMSE: 0.17357343435287476\n",
      "Epoch 251, Train_RMSE: 0.17339766025543213, Test MAE: 0.12808160483837128, Test_RMSE: 0.17353764176368713\n",
      "Epoch 252, Train_RMSE: 0.1733618974685669, Test MAE: 0.12805233895778656, Test_RMSE: 0.17350205779075623\n",
      "Epoch 253, Train_RMSE: 0.17332638800144196, Test MAE: 0.12802235782146454, Test_RMSE: 0.1734665036201477\n",
      "Epoch 254, Train_RMSE: 0.17329104244709015, Test MAE: 0.12799522280693054, Test_RMSE: 0.17343123257160187\n",
      "Epoch 255, Train_RMSE: 0.17325574159622192, Test MAE: 0.1279696822166443, Test_RMSE: 0.1733963042497635\n",
      "Epoch 256, Train_RMSE: 0.17322076857089996, Test MAE: 0.12794160842895508, Test_RMSE: 0.17336151003837585\n",
      "Epoch 257, Train_RMSE: 0.1731860488653183, Test MAE: 0.12791480123996735, Test_RMSE: 0.17332686483860016\n",
      "Epoch 258, Train_RMSE: 0.17315144836902618, Test MAE: 0.12789008021354675, Test_RMSE: 0.1732926070690155\n",
      "Epoch 259, Train_RMSE: 0.17311707139015198, Test MAE: 0.1278637796640396, Test_RMSE: 0.17325840890407562\n",
      "Epoch 260, Train_RMSE: 0.17308305203914642, Test MAE: 0.12783703207969666, Test_RMSE: 0.17322345077991486\n",
      "Epoch 261, Train_RMSE: 0.17304888367652893, Test MAE: 0.12781073153018951, Test_RMSE: 0.17318955063819885\n",
      "Epoch 262, Train_RMSE: 0.1730150282382965, Test MAE: 0.12778471410274506, Test_RMSE: 0.17315581440925598\n",
      "Epoch 263, Train_RMSE: 0.17298144102096558, Test MAE: 0.12775875627994537, Test_RMSE: 0.17312228679656982\n",
      "Epoch 264, Train_RMSE: 0.17294763028621674, Test MAE: 0.1277337521314621, Test_RMSE: 0.17308887839317322\n",
      "Epoch 265, Train_RMSE: 0.172914057970047, Test MAE: 0.1277119368314743, Test_RMSE: 0.17305579781532288\n",
      "Epoch 266, Train_RMSE: 0.1728808879852295, Test MAE: 0.1276864856481552, Test_RMSE: 0.17302274703979492\n",
      "Epoch 267, Train_RMSE: 0.1728476732969284, Test MAE: 0.12766140699386597, Test_RMSE: 0.1729898750782013\n",
      "Epoch 268, Train_RMSE: 0.17281469702720642, Test MAE: 0.12763658165931702, Test_RMSE: 0.17295712232589722\n",
      "Epoch 269, Train_RMSE: 0.17278195917606354, Test MAE: 0.12761163711547852, Test_RMSE: 0.17292456328868866\n",
      "Epoch 270, Train_RMSE: 0.1727493703365326, Test MAE: 0.12758688628673553, Test_RMSE: 0.1728922724723816\n",
      "Epoch 271, Train_RMSE: 0.1727171689271927, Test MAE: 0.12756039202213287, Test_RMSE: 0.17286023497581482\n",
      "Epoch 272, Train_RMSE: 0.1726849377155304, Test MAE: 0.127535879611969, Test_RMSE: 0.1728282868862152\n",
      "Epoch 273, Train_RMSE: 0.17265290021896362, Test MAE: 0.1275113970041275, Test_RMSE: 0.17279641330242157\n",
      "Epoch 274, Train_RMSE: 0.17262107133865356, Test MAE: 0.12748710811138153, Test_RMSE: 0.17276470363140106\n",
      "Epoch 275, Train_RMSE: 0.17258931696414948, Test MAE: 0.1274602711200714, Test_RMSE: 0.1727330982685089\n",
      "Epoch 276, Train_RMSE: 0.17255765199661255, Test MAE: 0.12743671238422394, Test_RMSE: 0.17270176112651825\n",
      "Epoch 277, Train_RMSE: 0.17252622544765472, Test MAE: 0.12741303443908691, Test_RMSE: 0.17267048358917236\n",
      "Epoch 278, Train_RMSE: 0.1724947839975357, Test MAE: 0.1273920089006424, Test_RMSE: 0.17263947427272797\n",
      "Epoch 279, Train_RMSE: 0.17246371507644653, Test MAE: 0.12736792862415314, Test_RMSE: 0.17260850965976715\n",
      "Epoch 280, Train_RMSE: 0.17243272066116333, Test MAE: 0.12734225392341614, Test_RMSE: 0.17257775366306305\n",
      "Epoch 281, Train_RMSE: 0.17240147292613983, Test MAE: 0.12731944024562836, Test_RMSE: 0.17254717648029327\n",
      "Epoch 282, Train_RMSE: 0.17237068712711334, Test MAE: 0.12729601562023163, Test_RMSE: 0.17251667380332947\n",
      "Epoch 283, Train_RMSE: 0.17234022915363312, Test MAE: 0.12727272510528564, Test_RMSE: 0.17248636484146118\n",
      "Epoch 284, Train_RMSE: 0.1723099648952484, Test MAE: 0.1272498518228531, Test_RMSE: 0.17245616018772125\n",
      "Epoch 285, Train_RMSE: 0.17227979004383087, Test MAE: 0.12722539901733398, Test_RMSE: 0.17242610454559326\n",
      "Epoch 286, Train_RMSE: 0.17224951088428497, Test MAE: 0.1272028088569641, Test_RMSE: 0.1723962426185608\n",
      "Epoch 287, Train_RMSE: 0.17221961915493011, Test MAE: 0.12717953324317932, Test_RMSE: 0.17236651480197906\n",
      "Epoch 288, Train_RMSE: 0.172189861536026, Test MAE: 0.127157062292099, Test_RMSE: 0.17233692109584808\n",
      "Epoch 289, Train_RMSE: 0.17216020822525024, Test MAE: 0.127134308218956, Test_RMSE: 0.17230738699436188\n",
      "Epoch 290, Train_RMSE: 0.17213082313537598, Test MAE: 0.12711147964000702, Test_RMSE: 0.17227816581726074\n",
      "Epoch 291, Train_RMSE: 0.17210154235363007, Test MAE: 0.12708765268325806, Test_RMSE: 0.17224879562854767\n",
      "Epoch 292, Train_RMSE: 0.17207252979278564, Test MAE: 0.12706398963928223, Test_RMSE: 0.17221975326538086\n",
      "Epoch 293, Train_RMSE: 0.1720436066389084, Test MAE: 0.12703979015350342, Test_RMSE: 0.1721908003091812\n",
      "Epoch 294, Train_RMSE: 0.17201469838619232, Test MAE: 0.12701667845249176, Test_RMSE: 0.17216211557388306\n",
      "Epoch 295, Train_RMSE: 0.17198599874973297, Test MAE: 0.12699462473392487, Test_RMSE: 0.17213353514671326\n",
      "Epoch 296, Train_RMSE: 0.17195755243301392, Test MAE: 0.12697170674800873, Test_RMSE: 0.1721051186323166\n",
      "Epoch 297, Train_RMSE: 0.17192919552326202, Test MAE: 0.12694774568080902, Test_RMSE: 0.17207683622837067\n",
      "Epoch 298, Train_RMSE: 0.1719009280204773, Test MAE: 0.12692546844482422, Test_RMSE: 0.1720486283302307\n",
      "Epoch 299, Train_RMSE: 0.1718728393316269, Test MAE: 0.12690195441246033, Test_RMSE: 0.17202064394950867\n",
      "Epoch 300, Train_RMSE: 0.17184481024742126, Test MAE: 0.12687978148460388, Test_RMSE: 0.17199280858039856\n",
      "Epoch 301, Train_RMSE: 0.17181691527366638, Test MAE: 0.12685933709144592, Test_RMSE: 0.17196506261825562\n",
      "Epoch 302, Train_RMSE: 0.17178919911384583, Test MAE: 0.12683649361133575, Test_RMSE: 0.1719374656677246\n",
      "Epoch 303, Train_RMSE: 0.17176146805286407, Test MAE: 0.12681442499160767, Test_RMSE: 0.17190998792648315\n",
      "Epoch 304, Train_RMSE: 0.171734020113945, Test MAE: 0.12679247558116913, Test_RMSE: 0.17188280820846558\n",
      "Epoch 305, Train_RMSE: 0.171706423163414, Test MAE: 0.12678103148937225, Test_RMSE: 0.17185555398464203\n",
      "Epoch 306, Train_RMSE: 0.17167913913726807, Test MAE: 0.12676027417182922, Test_RMSE: 0.1718285232782364\n",
      "Epoch 307, Train_RMSE: 0.17165200412273407, Test MAE: 0.1267387866973877, Test_RMSE: 0.17180156707763672\n",
      "Epoch 308, Train_RMSE: 0.1716250479221344, Test MAE: 0.12671706080436707, Test_RMSE: 0.17177481949329376\n",
      "Epoch 309, Train_RMSE: 0.1715981811285019, Test MAE: 0.12669599056243896, Test_RMSE: 0.17174819111824036\n",
      "Epoch 310, Train_RMSE: 0.17157147824764252, Test MAE: 0.1266741305589676, Test_RMSE: 0.17172163724899292\n",
      "Epoch 311, Train_RMSE: 0.17154498398303986, Test MAE: 0.12665195763111115, Test_RMSE: 0.17169532179832458\n",
      "Epoch 312, Train_RMSE: 0.17151856422424316, Test MAE: 0.12662924826145172, Test_RMSE: 0.17166902124881744\n",
      "Epoch 313, Train_RMSE: 0.1714920848608017, Test MAE: 0.12660719454288483, Test_RMSE: 0.17164292931556702\n",
      "Epoch 314, Train_RMSE: 0.1714659035205841, Test MAE: 0.12658478319644928, Test_RMSE: 0.17161689698696136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 315, Train_RMSE: 0.17143985629081726, Test MAE: 0.1265629082918167, Test_RMSE: 0.17159110307693481\n",
      "Epoch 316, Train_RMSE: 0.1714138239622116, Test MAE: 0.12653887271881104, Test_RMSE: 0.1715657114982605\n",
      "Epoch 317, Train_RMSE: 0.17138810455799103, Test MAE: 0.12651686370372772, Test_RMSE: 0.1715400218963623\n",
      "Epoch 318, Train_RMSE: 0.17136245965957642, Test MAE: 0.12649458646774292, Test_RMSE: 0.17151451110839844\n",
      "Epoch 319, Train_RMSE: 0.17133702337741852, Test MAE: 0.12647294998168945, Test_RMSE: 0.17148913443088531\n",
      "Epoch 320, Train_RMSE: 0.17131158709526062, Test MAE: 0.12644991278648376, Test_RMSE: 0.171463742852211\n",
      "Epoch 321, Train_RMSE: 0.1712861955165863, Test MAE: 0.12642797827720642, Test_RMSE: 0.17143860459327698\n",
      "Epoch 322, Train_RMSE: 0.17126113176345825, Test MAE: 0.12640374898910522, Test_RMSE: 0.17141343653202057\n",
      "Epoch 323, Train_RMSE: 0.17123593389987946, Test MAE: 0.12638144195079803, Test_RMSE: 0.1713884174823761\n",
      "Epoch 324, Train_RMSE: 0.17121131718158722, Test MAE: 0.12635749578475952, Test_RMSE: 0.17136357724666595\n",
      "Epoch 325, Train_RMSE: 0.17118656635284424, Test MAE: 0.12633399665355682, Test_RMSE: 0.171338751912117\n",
      "Epoch 326, Train_RMSE: 0.17116181552410126, Test MAE: 0.1263117790222168, Test_RMSE: 0.1713140457868576\n",
      "Epoch 327, Train_RMSE: 0.17113719880580902, Test MAE: 0.1262894570827484, Test_RMSE: 0.17128951847553253\n",
      "Epoch 328, Train_RMSE: 0.17111268639564514, Test MAE: 0.1262674182653427, Test_RMSE: 0.171265110373497\n",
      "Epoch 329, Train_RMSE: 0.1710888296365738, Test MAE: 0.12623125314712524, Test_RMSE: 0.1712358593940735\n",
      "Epoch 330, Train_RMSE: 0.1710645854473114, Test MAE: 0.12620927393436432, Test_RMSE: 0.17121171951293945\n",
      "Epoch 331, Train_RMSE: 0.17104031145572662, Test MAE: 0.12618768215179443, Test_RMSE: 0.17118768393993378\n",
      "Epoch 332, Train_RMSE: 0.1710163652896881, Test MAE: 0.1261700540781021, Test_RMSE: 0.17116360366344452\n",
      "Epoch 333, Train_RMSE: 0.17099224030971527, Test MAE: 0.12615078687667847, Test_RMSE: 0.17113998532295227\n",
      "Epoch 334, Train_RMSE: 0.17096853256225586, Test MAE: 0.1261284351348877, Test_RMSE: 0.17111629247665405\n",
      "Epoch 335, Train_RMSE: 0.17094478011131287, Test MAE: 0.12611092627048492, Test_RMSE: 0.17109349370002747\n",
      "Epoch 336, Train_RMSE: 0.17092111706733704, Test MAE: 0.1260877102613449, Test_RMSE: 0.1710699498653412\n",
      "Epoch 337, Train_RMSE: 0.17089742422103882, Test MAE: 0.12606485188007355, Test_RMSE: 0.1710466891527176\n",
      "Epoch 338, Train_RMSE: 0.17087393999099731, Test MAE: 0.1260426938533783, Test_RMSE: 0.17102350294589996\n",
      "Epoch 339, Train_RMSE: 0.1708507239818573, Test MAE: 0.12602129578590393, Test_RMSE: 0.1710004061460495\n",
      "Epoch 340, Train_RMSE: 0.17082758247852325, Test MAE: 0.12599921226501465, Test_RMSE: 0.17097744345664978\n",
      "Epoch 341, Train_RMSE: 0.17080456018447876, Test MAE: 0.12597253918647766, Test_RMSE: 0.17095458507537842\n",
      "Epoch 342, Train_RMSE: 0.17078164219856262, Test MAE: 0.12594729661941528, Test_RMSE: 0.17093175649642944\n",
      "Epoch 343, Train_RMSE: 0.17075873911380768, Test MAE: 0.12592501938343048, Test_RMSE: 0.1709090769290924\n",
      "Epoch 344, Train_RMSE: 0.17073608934879303, Test MAE: 0.1259029656648636, Test_RMSE: 0.17088653147220612\n",
      "Epoch 345, Train_RMSE: 0.17071355879306793, Test MAE: 0.1258801519870758, Test_RMSE: 0.17086409032344818\n",
      "Epoch 346, Train_RMSE: 0.17069111764431, Test MAE: 0.12585808336734772, Test_RMSE: 0.17084169387817383\n",
      "Epoch 347, Train_RMSE: 0.17066827416419983, Test MAE: 0.12584833800792694, Test_RMSE: 0.170822411775589\n",
      "Epoch 348, Train_RMSE: 0.17064596712589264, Test MAE: 0.12582536041736603, Test_RMSE: 0.17080023884773254\n",
      "Epoch 349, Train_RMSE: 0.17062382400035858, Test MAE: 0.125803142786026, Test_RMSE: 0.17077822983264923\n",
      "Epoch 350, Train_RMSE: 0.1706017404794693, Test MAE: 0.12578058242797852, Test_RMSE: 0.1707562953233719\n",
      "Epoch 351, Train_RMSE: 0.17057977616786957, Test MAE: 0.12576010823249817, Test_RMSE: 0.17073456943035126\n",
      "Epoch 352, Train_RMSE: 0.17055797576904297, Test MAE: 0.12573809921741486, Test_RMSE: 0.1707129180431366\n",
      "Epoch 353, Train_RMSE: 0.1705363243818283, Test MAE: 0.125715970993042, Test_RMSE: 0.1706913709640503\n",
      "Epoch 354, Train_RMSE: 0.17051473259925842, Test MAE: 0.12569402158260345, Test_RMSE: 0.17066995799541473\n",
      "Epoch 355, Train_RMSE: 0.1704932451248169, Test MAE: 0.12567181885242462, Test_RMSE: 0.17064866423606873\n",
      "Epoch 356, Train_RMSE: 0.1704719364643097, Test MAE: 0.12564964592456818, Test_RMSE: 0.17062751948833466\n",
      "Epoch 357, Train_RMSE: 0.17045070230960846, Test MAE: 0.12562784552574158, Test_RMSE: 0.17060644924640656\n",
      "Epoch 358, Train_RMSE: 0.17042964696884155, Test MAE: 0.12560608983039856, Test_RMSE: 0.17058566212654114\n",
      "Epoch 359, Train_RMSE: 0.1704086810350418, Test MAE: 0.12558428943157196, Test_RMSE: 0.17056481540203094\n",
      "Epoch 360, Train_RMSE: 0.17038767039775848, Test MAE: 0.1255687028169632, Test_RMSE: 0.17054568231105804\n",
      "Epoch 361, Train_RMSE: 0.17036698758602142, Test MAE: 0.12554779648780823, Test_RMSE: 0.1705254316329956\n",
      "Epoch 362, Train_RMSE: 0.17034640908241272, Test MAE: 0.12552644312381744, Test_RMSE: 0.17050501704216003\n",
      "Epoch 363, Train_RMSE: 0.17032600939273834, Test MAE: 0.12550434470176697, Test_RMSE: 0.1704847365617752\n",
      "Epoch 364, Train_RMSE: 0.17030568420886993, Test MAE: 0.12548290193080902, Test_RMSE: 0.17046457529067993\n",
      "Epoch 365, Train_RMSE: 0.17028558254241943, Test MAE: 0.12546169757843018, Test_RMSE: 0.1704445630311966\n",
      "Epoch 366, Train_RMSE: 0.1702655851840973, Test MAE: 0.1254390925168991, Test_RMSE: 0.17042456567287445\n",
      "Epoch 367, Train_RMSE: 0.1702457219362259, Test MAE: 0.12541711330413818, Test_RMSE: 0.17040468752384186\n",
      "Epoch 368, Train_RMSE: 0.17022591829299927, Test MAE: 0.12539587914943695, Test_RMSE: 0.17038500308990479\n",
      "Epoch 369, Train_RMSE: 0.1702062487602234, Test MAE: 0.12537521123886108, Test_RMSE: 0.17036546766757965\n",
      "Epoch 370, Train_RMSE: 0.1701866239309311, Test MAE: 0.12535220384597778, Test_RMSE: 0.1703459471464157\n",
      "Epoch 371, Train_RMSE: 0.17016707360744476, Test MAE: 0.1253303438425064, Test_RMSE: 0.17032663524150848\n",
      "Epoch 372, Train_RMSE: 0.17014767229557037, Test MAE: 0.12531116604804993, Test_RMSE: 0.1703074872493744\n",
      "Epoch 373, Train_RMSE: 0.17012840509414673, Test MAE: 0.12529094517230988, Test_RMSE: 0.17028836905956268\n",
      "Epoch 374, Train_RMSE: 0.17010927200317383, Test MAE: 0.1252705454826355, Test_RMSE: 0.1702694147825241\n",
      "Epoch 375, Train_RMSE: 0.17009028792381287, Test MAE: 0.12525004148483276, Test_RMSE: 0.17025050520896912\n",
      "Epoch 376, Train_RMSE: 0.1700715273618698, Test MAE: 0.1252298802137375, Test_RMSE: 0.17023172974586487\n",
      "Epoch 377, Train_RMSE: 0.1700526773929596, Test MAE: 0.1252109706401825, Test_RMSE: 0.1702134758234024\n",
      "Epoch 378, Train_RMSE: 0.17003414034843445, Test MAE: 0.12519153952598572, Test_RMSE: 0.1701950579881668\n",
      "Epoch 379, Train_RMSE: 0.17001564800739288, Test MAE: 0.12517201900482178, Test_RMSE: 0.17017671465873718\n",
      "Epoch 380, Train_RMSE: 0.16999737918376923, Test MAE: 0.12515151500701904, Test_RMSE: 0.17015813291072845\n",
      "Epoch 381, Train_RMSE: 0.1699792444705963, Test MAE: 0.125131294131279, Test_RMSE: 0.17014001309871674\n",
      "Epoch 382, Train_RMSE: 0.16996100544929504, Test MAE: 0.1251162886619568, Test_RMSE: 0.17012305557727814\n",
      "Epoch 383, Train_RMSE: 0.16994312405586243, Test MAE: 0.12509703636169434, Test_RMSE: 0.17010517418384552\n",
      "Epoch 384, Train_RMSE: 0.16992533206939697, Test MAE: 0.12507782876491547, Test_RMSE: 0.17008741199970245\n",
      "Epoch 385, Train_RMSE: 0.16990771889686584, Test MAE: 0.12505879998207092, Test_RMSE: 0.17006970942020416\n",
      "Epoch 386, Train_RMSE: 0.1698901653289795, Test MAE: 0.12503960728645325, Test_RMSE: 0.17005209624767303\n",
      "Epoch 387, Train_RMSE: 0.16987276077270508, Test MAE: 0.12502121925354004, Test_RMSE: 0.17003466188907623\n",
      "Epoch 388, Train_RMSE: 0.16985541582107544, Test MAE: 0.12500563263893127, Test_RMSE: 0.17001815140247345\n",
      "Epoch 389, Train_RMSE: 0.16983819007873535, Test MAE: 0.12498848140239716, Test_RMSE: 0.1700010448694229\n",
      "Epoch 390, Train_RMSE: 0.16982123255729675, Test MAE: 0.12496902048587799, Test_RMSE: 0.16998372972011566\n",
      "Epoch 391, Train_RMSE: 0.16980405151844025, Test MAE: 0.1249501183629036, Test_RMSE: 0.16996674239635468\n",
      "Epoch 392, Train_RMSE: 0.16978704929351807, Test MAE: 0.1249321848154068, Test_RMSE: 0.16994979977607727\n",
      "Epoch 393, Train_RMSE: 0.1697702556848526, Test MAE: 0.12491451948881149, Test_RMSE: 0.1699330061674118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 394, Train_RMSE: 0.1697535514831543, Test MAE: 0.12489716708660126, Test_RMSE: 0.16991625726222992\n",
      "Epoch 395, Train_RMSE: 0.16973701119422913, Test MAE: 0.12487239390611649, Test_RMSE: 0.16989971697330475\n",
      "Epoch 396, Train_RMSE: 0.16972045600414276, Test MAE: 0.12485463917255402, Test_RMSE: 0.16988323628902435\n",
      "Epoch 397, Train_RMSE: 0.16970409452915192, Test MAE: 0.12483719736337662, Test_RMSE: 0.16986675560474396\n",
      "Epoch 398, Train_RMSE: 0.169687882065773, Test MAE: 0.12482089549303055, Test_RMSE: 0.16985058784484863\n",
      "Epoch 399, Train_RMSE: 0.16967181861400604, Test MAE: 0.12480100244283676, Test_RMSE: 0.1698344200849533\n",
      "Epoch 400, Train_RMSE: 0.16965563595294952, Test MAE: 0.12478309869766235, Test_RMSE: 0.16981840133666992\n",
      "Epoch 401, Train_RMSE: 0.16963955760002136, Test MAE: 0.12476504594087601, Test_RMSE: 0.1698027402162552\n",
      "Epoch 402, Train_RMSE: 0.16962367296218872, Test MAE: 0.12474755942821503, Test_RMSE: 0.16978685557842255\n",
      "Epoch 403, Train_RMSE: 0.16960790753364563, Test MAE: 0.12473098933696747, Test_RMSE: 0.16977111995220184\n",
      "Epoch 404, Train_RMSE: 0.16959218680858612, Test MAE: 0.1247146874666214, Test_RMSE: 0.1697555035352707\n",
      "Epoch 405, Train_RMSE: 0.16957664489746094, Test MAE: 0.12470287084579468, Test_RMSE: 0.16974006593227386\n",
      "Epoch 406, Train_RMSE: 0.16956113278865814, Test MAE: 0.12468583881855011, Test_RMSE: 0.16972459852695465\n",
      "Epoch 407, Train_RMSE: 0.16954538226127625, Test MAE: 0.12467794865369797, Test_RMSE: 0.16971080005168915\n",
      "Epoch 408, Train_RMSE: 0.16953009366989136, Test MAE: 0.12466209381818771, Test_RMSE: 0.16969557106494904\n",
      "Epoch 409, Train_RMSE: 0.16951481997966766, Test MAE: 0.12464620918035507, Test_RMSE: 0.1696804314851761\n",
      "Epoch 410, Train_RMSE: 0.16949982941150665, Test MAE: 0.12462975084781647, Test_RMSE: 0.1696654111146927\n",
      "Epoch 411, Train_RMSE: 0.16948489844799042, Test MAE: 0.12461435794830322, Test_RMSE: 0.16965046525001526\n",
      "Epoch 412, Train_RMSE: 0.16947002708911896, Test MAE: 0.12460058927536011, Test_RMSE: 0.16963578760623932\n",
      "Epoch 413, Train_RMSE: 0.16945531964302063, Test MAE: 0.12458495050668716, Test_RMSE: 0.16962113976478577\n",
      "Epoch 414, Train_RMSE: 0.16944049298763275, Test MAE: 0.12457186728715897, Test_RMSE: 0.16960638761520386\n",
      "Epoch 415, Train_RMSE: 0.16942577064037323, Test MAE: 0.12455723434686661, Test_RMSE: 0.1695917397737503\n",
      "Epoch 416, Train_RMSE: 0.16941127181053162, Test MAE: 0.12454261630773544, Test_RMSE: 0.1695771962404251\n",
      "Epoch 417, Train_RMSE: 0.16939684748649597, Test MAE: 0.12452813982963562, Test_RMSE: 0.1695627123117447\n",
      "Epoch 418, Train_RMSE: 0.16938261687755585, Test MAE: 0.12451343983411789, Test_RMSE: 0.16954836249351501\n",
      "Epoch 419, Train_RMSE: 0.1693684309720993, Test MAE: 0.1244988888502121, Test_RMSE: 0.16953414678573608\n",
      "Epoch 420, Train_RMSE: 0.16935449838638306, Test MAE: 0.12447894364595413, Test_RMSE: 0.16952000558376312\n",
      "Epoch 421, Train_RMSE: 0.1693403720855713, Test MAE: 0.1244642585515976, Test_RMSE: 0.1695060133934021\n",
      "Epoch 422, Train_RMSE: 0.16932640969753265, Test MAE: 0.12444966286420822, Test_RMSE: 0.16949206590652466\n",
      "Epoch 423, Train_RMSE: 0.1693125069141388, Test MAE: 0.1244356706738472, Test_RMSE: 0.16947832703590393\n",
      "Epoch 424, Train_RMSE: 0.16929882764816284, Test MAE: 0.12442153692245483, Test_RMSE: 0.169464573264122\n",
      "Epoch 425, Train_RMSE: 0.16928505897521973, Test MAE: 0.12440745532512665, Test_RMSE: 0.16945089399814606\n",
      "Epoch 426, Train_RMSE: 0.1692715585231781, Test MAE: 0.12439412623643875, Test_RMSE: 0.1694374680519104\n",
      "Epoch 427, Train_RMSE: 0.16925808787345886, Test MAE: 0.1243811622262001, Test_RMSE: 0.16942426562309265\n",
      "Epoch 428, Train_RMSE: 0.16924476623535156, Test MAE: 0.12436848133802414, Test_RMSE: 0.1694110482931137\n",
      "Epoch 429, Train_RMSE: 0.16923147439956665, Test MAE: 0.12435499578714371, Test_RMSE: 0.16939778625965118\n",
      "Epoch 430, Train_RMSE: 0.16921833157539368, Test MAE: 0.12434221059083939, Test_RMSE: 0.1693846881389618\n",
      "Epoch 431, Train_RMSE: 0.16920532286167145, Test MAE: 0.12432962656021118, Test_RMSE: 0.16937170922756195\n",
      "Epoch 432, Train_RMSE: 0.1691923886537552, Test MAE: 0.12431727349758148, Test_RMSE: 0.1693587601184845\n",
      "Epoch 433, Train_RMSE: 0.1691795289516449, Test MAE: 0.12430509924888611, Test_RMSE: 0.16934587061405182\n",
      "Epoch 434, Train_RMSE: 0.16916680335998535, Test MAE: 0.12429317831993103, Test_RMSE: 0.16933311522006989\n",
      "Epoch 435, Train_RMSE: 0.16915418207645416, Test MAE: 0.12428150326013565, Test_RMSE: 0.16932043433189392\n",
      "Epoch 436, Train_RMSE: 0.16914159059524536, Test MAE: 0.12427069991827011, Test_RMSE: 0.1693079024553299\n",
      "Epoch 437, Train_RMSE: 0.16912902891635895, Test MAE: 0.1242595687508583, Test_RMSE: 0.16929535567760468\n",
      "Epoch 438, Train_RMSE: 0.16911685466766357, Test MAE: 0.12424180656671524, Test_RMSE: 0.1692829728126526\n",
      "Epoch 439, Train_RMSE: 0.1691044569015503, Test MAE: 0.12422829866409302, Test_RMSE: 0.1692705750465393\n",
      "Epoch 440, Train_RMSE: 0.1690923124551773, Test MAE: 0.12421520799398422, Test_RMSE: 0.16925787925720215\n",
      "Epoch 441, Train_RMSE: 0.16908013820648193, Test MAE: 0.12420279532670975, Test_RMSE: 0.16924558579921722\n",
      "Epoch 442, Train_RMSE: 0.16906778514385223, Test MAE: 0.1241905465722084, Test_RMSE: 0.16923335194587708\n",
      "Epoch 443, Train_RMSE: 0.16905556619167328, Test MAE: 0.12417933344841003, Test_RMSE: 0.16922125220298767\n",
      "Epoch 444, Train_RMSE: 0.16904355585575104, Test MAE: 0.1241680160164833, Test_RMSE: 0.16920921206474304\n",
      "Epoch 445, Train_RMSE: 0.1690312772989273, Test MAE: 0.12415774166584015, Test_RMSE: 0.1691971868276596\n",
      "Epoch 446, Train_RMSE: 0.16901938617229462, Test MAE: 0.12414617091417313, Test_RMSE: 0.16918489336967468\n",
      "Epoch 447, Train_RMSE: 0.16900767385959625, Test MAE: 0.12413289397954941, Test_RMSE: 0.16917301714420319\n",
      "Epoch 448, Train_RMSE: 0.16899581253528595, Test MAE: 0.12412172555923462, Test_RMSE: 0.16916121542453766\n",
      "Epoch 449, Train_RMSE: 0.16898414492607117, Test MAE: 0.12411072105169296, Test_RMSE: 0.1691495031118393\n",
      "Epoch 450, Train_RMSE: 0.16897249221801758, Test MAE: 0.12409962713718414, Test_RMSE: 0.16913780570030212\n",
      "Epoch 451, Train_RMSE: 0.16896086931228638, Test MAE: 0.12408962100744247, Test_RMSE: 0.1691264510154724\n",
      "Epoch 452, Train_RMSE: 0.16894935071468353, Test MAE: 0.12407856434583664, Test_RMSE: 0.1691148579120636\n",
      "Epoch 453, Train_RMSE: 0.16893790662288666, Test MAE: 0.1240679994225502, Test_RMSE: 0.1691034436225891\n",
      "Epoch 454, Train_RMSE: 0.16892653703689575, Test MAE: 0.12405872344970703, Test_RMSE: 0.1690921038389206\n",
      "Epoch 455, Train_RMSE: 0.1689152717590332, Test MAE: 0.12404833734035492, Test_RMSE: 0.16908079385757446\n",
      "Epoch 456, Train_RMSE: 0.16890399158000946, Test MAE: 0.12403794378042221, Test_RMSE: 0.16906961798667908\n",
      "Epoch 457, Train_RMSE: 0.16889292001724243, Test MAE: 0.12402772158384323, Test_RMSE: 0.1690584272146225\n",
      "Epoch 458, Train_RMSE: 0.16888181865215302, Test MAE: 0.1240176185965538, Test_RMSE: 0.1690472513437271\n",
      "Epoch 459, Train_RMSE: 0.16887077689170837, Test MAE: 0.12400782853364944, Test_RMSE: 0.16903623938560486\n",
      "Epoch 460, Train_RMSE: 0.1688597947359085, Test MAE: 0.12399810552597046, Test_RMSE: 0.1690252423286438\n",
      "Epoch 461, Train_RMSE: 0.16884887218475342, Test MAE: 0.12398795038461685, Test_RMSE: 0.16901430487632751\n",
      "Epoch 462, Train_RMSE: 0.16883811354637146, Test MAE: 0.12397823482751846, Test_RMSE: 0.1690034121274948\n",
      "Epoch 463, Train_RMSE: 0.16882732510566711, Test MAE: 0.12396585196256638, Test_RMSE: 0.1689925491809845\n",
      "Epoch 464, Train_RMSE: 0.16881652176380157, Test MAE: 0.12395437806844711, Test_RMSE: 0.168981671333313\n",
      "Epoch 465, Train_RMSE: 0.16880583763122559, Test MAE: 0.12394504994153976, Test_RMSE: 0.1689709722995758\n",
      "Epoch 466, Train_RMSE: 0.16879518330097198, Test MAE: 0.12393558770418167, Test_RMSE: 0.16896024346351624\n",
      "Epoch 467, Train_RMSE: 0.16878461837768555, Test MAE: 0.12392629683017731, Test_RMSE: 0.16894972324371338\n",
      "Epoch 468, Train_RMSE: 0.16877400875091553, Test MAE: 0.12391705811023712, Test_RMSE: 0.1689390242099762\n",
      "Epoch 469, Train_RMSE: 0.16876354813575745, Test MAE: 0.1239074096083641, Test_RMSE: 0.16892853379249573\n",
      "Epoch 470, Train_RMSE: 0.16875311732292175, Test MAE: 0.12389818578958511, Test_RMSE: 0.16891804337501526\n",
      "Epoch 471, Train_RMSE: 0.16874270141124725, Test MAE: 0.12388908118009567, Test_RMSE: 0.16890756785869598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 472, Train_RMSE: 0.1687324345111847, Test MAE: 0.12388008087873459, Test_RMSE: 0.16889722645282745\n",
      "Epoch 473, Train_RMSE: 0.16872215270996094, Test MAE: 0.12387107312679291, Test_RMSE: 0.16888682544231415\n",
      "Epoch 474, Train_RMSE: 0.16871167719364166, Test MAE: 0.12386107444763184, Test_RMSE: 0.16887660324573517\n",
      "Epoch 475, Train_RMSE: 0.16870151460170746, Test MAE: 0.12385261058807373, Test_RMSE: 0.1688663810491562\n",
      "Epoch 476, Train_RMSE: 0.16869129240512848, Test MAE: 0.1238444373011589, Test_RMSE: 0.1688561737537384\n",
      "Epoch 477, Train_RMSE: 0.16868111491203308, Test MAE: 0.12383559346199036, Test_RMSE: 0.168845996260643\n",
      "Epoch 478, Train_RMSE: 0.16867105662822723, Test MAE: 0.1238265112042427, Test_RMSE: 0.16883577406406403\n",
      "Epoch 479, Train_RMSE: 0.168660968542099, Test MAE: 0.12381748855113983, Test_RMSE: 0.1688256412744522\n",
      "Epoch 480, Train_RMSE: 0.16865086555480957, Test MAE: 0.1238086149096489, Test_RMSE: 0.1688155233860016\n",
      "Epoch 481, Train_RMSE: 0.16864092648029327, Test MAE: 0.12379980832338333, Test_RMSE: 0.16880545020103455\n",
      "Epoch 482, Train_RMSE: 0.16863085329532623, Test MAE: 0.12379033863544464, Test_RMSE: 0.16879530251026154\n",
      "Epoch 483, Train_RMSE: 0.16862092912197113, Test MAE: 0.12378082424402237, Test_RMSE: 0.16878531873226166\n",
      "Epoch 484, Train_RMSE: 0.16861103475093842, Test MAE: 0.1237717792391777, Test_RMSE: 0.16877532005310059\n",
      "Epoch 485, Train_RMSE: 0.1686011701822281, Test MAE: 0.1237630769610405, Test_RMSE: 0.1687653809785843\n",
      "Epoch 486, Train_RMSE: 0.16859130561351776, Test MAE: 0.12375413626432419, Test_RMSE: 0.1687553972005844\n",
      "Epoch 487, Train_RMSE: 0.16858145594596863, Test MAE: 0.12374620884656906, Test_RMSE: 0.16874569654464722\n",
      "Epoch 488, Train_RMSE: 0.16857166588306427, Test MAE: 0.12373753637075424, Test_RMSE: 0.16873593628406525\n",
      "Epoch 489, Train_RMSE: 0.16856196522712708, Test MAE: 0.12372899055480957, Test_RMSE: 0.16872607171535492\n",
      "Epoch 490, Train_RMSE: 0.1685522049665451, Test MAE: 0.12372052669525146, Test_RMSE: 0.1687162220478058\n",
      "Epoch 491, Train_RMSE: 0.1685425490140915, Test MAE: 0.12371203303337097, Test_RMSE: 0.1687064915895462\n",
      "Epoch 492, Train_RMSE: 0.1685328483581543, Test MAE: 0.12370377779006958, Test_RMSE: 0.16869674623012543\n",
      "Epoch 493, Train_RMSE: 0.16852319240570068, Test MAE: 0.12369532883167267, Test_RMSE: 0.16868695616722107\n",
      "Epoch 494, Train_RMSE: 0.16851355135440826, Test MAE: 0.12368699908256531, Test_RMSE: 0.16867731511592865\n",
      "Epoch 495, Train_RMSE: 0.1685040295124054, Test MAE: 0.12367844581604004, Test_RMSE: 0.16866756975650787\n",
      "Epoch 496, Train_RMSE: 0.16849394142627716, Test MAE: 0.12367107719182968, Test_RMSE: 0.168660506606102\n",
      "Epoch 497, Train_RMSE: 0.1684844046831131, Test MAE: 0.12366189807653427, Test_RMSE: 0.168650820851326\n",
      "Epoch 498, Train_RMSE: 0.16847480833530426, Test MAE: 0.12365304678678513, Test_RMSE: 0.16864117980003357\n",
      "Epoch 499, Train_RMSE: 0.1684652417898178, Test MAE: 0.12364400923252106, Test_RMSE: 0.16863149404525757\n",
      "Epoch 500, Train_RMSE: 0.16845567524433136, Test MAE: 0.12363512814044952, Test_RMSE: 0.16862177848815918\n",
      "Epoch 501, Train_RMSE: 0.1684461236000061, Test MAE: 0.12362577766180038, Test_RMSE: 0.1686122715473175\n",
      "Epoch 502, Train_RMSE: 0.16843657195568085, Test MAE: 0.12361711263656616, Test_RMSE: 0.16860266029834747\n",
      "Epoch 503, Train_RMSE: 0.16842710971832275, Test MAE: 0.12360824644565582, Test_RMSE: 0.16859300434589386\n",
      "Epoch 504, Train_RMSE: 0.16841758787631989, Test MAE: 0.12359914928674698, Test_RMSE: 0.16858336329460144\n",
      "Epoch 505, Train_RMSE: 0.1684078872203827, Test MAE: 0.12359008938074112, Test_RMSE: 0.16857367753982544\n",
      "Epoch 506, Train_RMSE: 0.16839846968650818, Test MAE: 0.1235814169049263, Test_RMSE: 0.16856403648853302\n",
      "Epoch 507, Train_RMSE: 0.16838888823986053, Test MAE: 0.1235717386007309, Test_RMSE: 0.16855454444885254\n",
      "Epoch 508, Train_RMSE: 0.16837932169437408, Test MAE: 0.12356217205524445, Test_RMSE: 0.16854500770568848\n",
      "Epoch 509, Train_RMSE: 0.16836987435817719, Test MAE: 0.12355303019285202, Test_RMSE: 0.16853538155555725\n",
      "Epoch 510, Train_RMSE: 0.16836044192314148, Test MAE: 0.12354396283626556, Test_RMSE: 0.16852575540542603\n",
      "Epoch 511, Train_RMSE: 0.1683509796857834, Test MAE: 0.1235349103808403, Test_RMSE: 0.16851618885993958\n",
      "Epoch 512, Train_RMSE: 0.1683415323495865, Test MAE: 0.1235261857509613, Test_RMSE: 0.16850654780864716\n",
      "Epoch 513, Train_RMSE: 0.16833212971687317, Test MAE: 0.12351717799901962, Test_RMSE: 0.1684969663619995\n",
      "Epoch 514, Train_RMSE: 0.16832266747951508, Test MAE: 0.12350816279649734, Test_RMSE: 0.16848741471767426\n",
      "Epoch 515, Train_RMSE: 0.16831329464912415, Test MAE: 0.12349919974803925, Test_RMSE: 0.16847775876522064\n",
      "Epoch 516, Train_RMSE: 0.16830384731292725, Test MAE: 0.1234903410077095, Test_RMSE: 0.1684681922197342\n",
      "Epoch 517, Train_RMSE: 0.16829434037208557, Test MAE: 0.12348146736621857, Test_RMSE: 0.16845861077308655\n",
      "Epoch 518, Train_RMSE: 0.16828492283821106, Test MAE: 0.12347282469272614, Test_RMSE: 0.1684490144252777\n",
      "Epoch 519, Train_RMSE: 0.16827556490898132, Test MAE: 0.12346401810646057, Test_RMSE: 0.16843938827514648\n",
      "Epoch 520, Train_RMSE: 0.16826605796813965, Test MAE: 0.12345493584871292, Test_RMSE: 0.16842973232269287\n",
      "Epoch 521, Train_RMSE: 0.16825659573078156, Test MAE: 0.1234467402100563, Test_RMSE: 0.16842009127140045\n",
      "Epoch 522, Train_RMSE: 0.1682470142841339, Test MAE: 0.12343767285346985, Test_RMSE: 0.16841043531894684\n",
      "Epoch 523, Train_RMSE: 0.1682375967502594, Test MAE: 0.12342851608991623, Test_RMSE: 0.16840073466300964\n",
      "Epoch 524, Train_RMSE: 0.1682281643152237, Test MAE: 0.12341770529747009, Test_RMSE: 0.16839073598384857\n",
      "Epoch 525, Train_RMSE: 0.1682186871767044, Test MAE: 0.12340842932462692, Test_RMSE: 0.16838110983371735\n",
      "Epoch 526, Train_RMSE: 0.1682092249393463, Test MAE: 0.12339872121810913, Test_RMSE: 0.16837142407894135\n",
      "Epoch 527, Train_RMSE: 0.16819967329502106, Test MAE: 0.12337999045848846, Test_RMSE: 0.16836194694042206\n",
      "Epoch 528, Train_RMSE: 0.1681903600692749, Test MAE: 0.12336812913417816, Test_RMSE: 0.16835221648216248\n",
      "Epoch 529, Train_RMSE: 0.16818083822727203, Test MAE: 0.12335872650146484, Test_RMSE: 0.16834262013435364\n",
      "Epoch 530, Train_RMSE: 0.168171226978302, Test MAE: 0.12334897369146347, Test_RMSE: 0.1683327853679657\n",
      "Epoch 531, Train_RMSE: 0.16816169023513794, Test MAE: 0.12333865463733673, Test_RMSE: 0.16832299530506134\n",
      "Epoch 532, Train_RMSE: 0.16815204918384552, Test MAE: 0.1233283281326294, Test_RMSE: 0.1683131605386734\n",
      "Epoch 533, Train_RMSE: 0.16814222931861877, Test MAE: 0.12331564724445343, Test_RMSE: 0.16830332577228546\n",
      "Epoch 534, Train_RMSE: 0.16813240945339203, Test MAE: 0.12330720573663712, Test_RMSE: 0.16829359531402588\n",
      "Epoch 535, Train_RMSE: 0.16812263429164886, Test MAE: 0.12329725921154022, Test_RMSE: 0.1682836413383484\n",
      "Epoch 536, Train_RMSE: 0.16811281442642212, Test MAE: 0.12328722327947617, Test_RMSE: 0.16827359795570374\n",
      "Epoch 537, Train_RMSE: 0.1681029498577118, Test MAE: 0.12327712774276733, Test_RMSE: 0.16826362907886505\n",
      "Epoch 538, Train_RMSE: 0.16809307038784027, Test MAE: 0.12326706945896149, Test_RMSE: 0.168253555893898\n",
      "Epoch 539, Train_RMSE: 0.16808316111564636, Test MAE: 0.12325694411993027, Test_RMSE: 0.1682434380054474\n",
      "Epoch 540, Train_RMSE: 0.16807319223880768, Test MAE: 0.12324678897857666, Test_RMSE: 0.16823330521583557\n"
     ]
    }
   ],
   "source": [
    "# with the distributed input.\n",
    "@tf.function\n",
    "def distributed_train_step_batch(dataset_inputs):\n",
    "    per_replica_losses = strategy.run(train_step_batch, args=(dataset_inputs,)) \n",
    "    return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,\n",
    "                         axis=None)\n",
    "@tf.function\n",
    "def collaborative_predictions(dataset_inputs):\n",
    "    per_replica_predictions= strategy.run(train_step_sample, args=(dataset_inputs,))\n",
    "    return strategy.reduce(tf.distribute.ReduceOp.MEAN, per_replica_predictions,  \n",
    "                         axis=None)\n",
    "@tf.function\n",
    "def local_collaborative_loss(collaborative_predictions, dataset_inputs):\n",
    "    return strategy.run(compute_loss_fedLabSync, args=(dataset_inputs, collaborative_predictions,))\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # TRAIN LOOP\n",
    "    total_loss = 0.0\n",
    "    #num_batches = 0\n",
    "    for x in local_result_train:\n",
    "        colaboratePrediction = collaborative_predictions(x)\n",
    "        total_loss += local_collaborative_loss(colaboratePrediction, x)\n",
    "        #total_loss += distributed_train_step_batch(x)\n",
    "        num_batches += 1\n",
    "    train_loss = total_loss / num_batches\n",
    "    \n",
    "    # TEST LOOP\n",
    "    for x in local_result_test:\n",
    "        distributed_test_step_batch(x)\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        checkpoint.save(checkpoint_prefix)\n",
    "\n",
    "    template = (\"Epoch {}, Train_RMSE: {}, Test MAE: {}, \"\n",
    "              \"Test_RMSE: {}\")\n",
    "    print(template.format(epoch + 1, train_rmse.result(), test_mae.result(),\n",
    "                         test_rmse.result()))\n",
    "    test_mae.reset_states()\n",
    "    train_rmse.reset_states()\n",
    "    test_rmse.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3915a20c",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "6f62f7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "routes_test = {}\n",
    "test_df = pq.read_table(OUT_PATH + 'test_fd00' + str(NUMBER_OF_DATASET)+'.parquet').to_pandas()\n",
    "for unit_nr in test_df['id'].unique():\n",
    "    routes_test[unit_nr-1] = test_df.loc[test_df['id'] == unit_nr]\n",
    "RC=120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "62922ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAJECTORY=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23f99a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 2s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 6ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "routes_kalman = []\n",
    "rul_predicted=np.array([])\n",
    "rul_truth=np.array([])\n",
    "Score=0\n",
    "#writer = pd.ExcelWriter('RUL_Test_FD004_Turbofan.xlsx', engine='xlsxwriter')\n",
    "for route_test in routes_test:\n",
    "    # Define a dictionary containing Students data \n",
    "    data = {} \n",
    "    # Convert the dictionary into DataFrame \n",
    "    df = pd.DataFrame(data)\n",
    "    #Obtaining rul - groud truth\n",
    "    truth_dataframe=routes_test[route_test]['RUL']\n",
    "    truth=np.array(truth_dataframe.values.tolist())*RC\n",
    "    rul_truth=np.append(rul_truth,truth)\n",
    "    #Obtaining rul - predicted\n",
    "    trajectory = routes_test[route_test][SENSOR_COLS].to_numpy()\n",
    "    rul_trajectory=model.predict(trajectory)\n",
    "    rul_trajectory = pd.DataFrame(rul_trajectory, columns=['rul'])\n",
    "    z = np.array(rul_trajectory.values.tolist())\n",
    "    # intial parameters\n",
    "    n_iter = len(rul_trajectory)\n",
    "    sz = (len(rul_trajectory),) # size of array\n",
    "    # process variance\n",
    "    #Q=1/209\n",
    "    Q = 1/209\n",
    "    # allocate space for arrays\n",
    "    xhat=np.zeros(sz)      # a posteri estimate of x\n",
    "    P=np.zeros(sz)         # a posteri error estimate\n",
    "    xhatminus=np.zeros(sz) # a priori estimate of x\n",
    "    Pminus=np.zeros(sz)    # a priori error estimate\n",
    "    K=np.zeros(sz)         # gain or blending factor\n",
    "\n",
    "    R = 0.3**2 # estimate of measurement variance, change to see effect\n",
    "    # intial guesses\n",
    "    #xhat[0] = 1\n",
    "    xhat[0]=truth[0]/RC\n",
    "    P[0] = 0.0\n",
    "\n",
    "    for k in range(1,n_iter):\n",
    "        # time update\n",
    "        xhatminus[k] = xhat[k-1]\n",
    "        Pminus[k] = P[k-1]+Q\n",
    "        # measurement update\n",
    "        K[k] = Pminus[k]/( Pminus[k]+R )\n",
    "        xhat[k] = xhatminus[k]+K[k]*(z[k]-xhatminus[k])\n",
    "        P[k] = (1-K[k])*Pminus[k]\n",
    "        if(xhat[k]-truth[k]<0):\n",
    "            score=math.exp((truth[k]-xhat[k])/13)-1;\n",
    "        if (xhat[k]-truth[k]>=0):\n",
    "            score=math.exp((xhat[k]-truth[k])/10)-1;\n",
    "        Score=Score+score;\n",
    "    \n",
    "    xhat=xhat*RC\n",
    "    rul_predicted=np.append(rul_predicted,xhat)\n",
    "    routes_kalman.insert((unit_nr-1),xhat[(len(xhat)-1)])\n",
    "\n",
    "    if route_test==TRAJECTORY:\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.plot(truth,'g-',label='ground truth')\n",
    "        plt.plot(z*RC,'r-',label='estimate')\n",
    "        plt.plot(xhat,'b-',label='a posteri estimate')\n",
    "        plt.legend(['ground truth','estimated','filtered'])\n",
    "        #plt.title('RUL vs cycle', fontweight='bold')\n",
    "        plt.xlabel('Cycle')\n",
    "        plt.ylabel('RUL')\n",
    "        plt.show()\n",
    "#writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc4bfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mae=mean_absolute_error(rul_predicted,rul_truth)\n",
    "mse=mean_squared_error(rul_predicted,rul_truth)\n",
    "rmse=np.sqrt(mse)\n",
    "print(\"GAUSSIAN KALMAN\")\n",
    "print(\"MAE:\",mae)\n",
    "print(\"MSE:\",mse)\n",
    "print(\"RMSE:\",rmse)\n",
    "#print(\"Score:\",Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b57578a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dd9859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149f3b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
